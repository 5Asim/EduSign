0:00 so this is exactly a project in which we will be working today you can see that this is a sign language detector we are
0:06 currently detecting different signs I am doing with my hands these are three signs I have selected from the American
0:11 sign language alphabet from this alphabet I have over here I have selected the letter A the letter b and
0:17 the letter L but obviously we could apply exactly the same process to absolutely any other symbol absolutely
0:24 any other sign from this alphabet or from any other sign language alphabet from any other country so this is
0:30 exactly a project in which we will be working on today's tutorial this will be 100 in Python we are going to be using
0:37 opencv media pipe we are going to be addicting the landmarks from our hands so this is going to be an amazing
0:42 tutorial and let's get started so this is exactly the project in which we are going to be working today and now let me
0:49 show you the pycharm project I created for today's tutorial we are going to work with these three requirements
0:56 obviously please remember to install these requirements before starting with this tutorial we are going to work with
1:01 opencv media pipe this is a very important Library we are going to use today and we're also going to work with
1:06 ckit learn so these are the requirements for today's tutorial and now let me tell
1:12 you about the project about the processing which we are going to be working today this will be a three steps
1:18 process and this is actually a very classical machine learning process we are going to start with the data
1:24 preparation the data creation then we're going to train the model and then we're going to test how this model performs so
1:31 these are the three steps in which we are going to be working today now in order to get started with this
1:37 tutorial I have already created a script which is going to be super super helpful in order to create our data set this is
1:44 a script I have already created so we can save some time while we are working
1:49 onto this tutorial so we can focus our energy on everything else because everything else will be much much more
1:55 important so you can see that this is my webcam and I have a message on my webcam saying ready and if ready press the
2:02 letter Q so the way we are going to use this script the way we are going to use this uh webcam is that we are going to
2:10 collect many different samples of the three symbols I shall show you right so
2:16 what I'm going to do is for example for the letter A for this symbol which represent the letter A I'm going to do
2:21 many times I'm going to do this process I'm going to move my hand towards the
2:26 camera and away from the camera and this way what I'm going to do is to create many different samples many different
2:33 examples of how the leather a it looks like right remember we are building a
2:39 classifier and the way classifiers work classifiers need data and the more data
2:44 we have or the more diverse data we have is going to be much better so I am going to do this this process
2:50 for the letter A then I'm going to repeat the same process for the letter b and then I'm going to do exactly the
2:55 same process for the letter L so we are going to repeat this process for these three symbols and this way we are going
3:01 to collect our data we are going to generate our data set that we are going
3:07 to create in order to work on today's tutorial so the idea is that once I'm ready I press the letter q and I start
3:13 collecting symbols I start collecting frames for all these different symbols so let's start there I'm going to press
3:19 the letter q and I'm going to move my hand towards the camera and away from the camera
3:25 and that's it so now I'm going to move to the next symbol which is something
3:31 this and I'm going to move my hand towards the camera and away from the camera
3:36 and I'm going to look for a few seconds and that's pretty much all I'm going to do the same with the letter L and I'm
3:44 going to move my hand towards the camera and away from the camera and I'm going to show you in a few
3:50 seconds how this data looks like so this is pretty much all now let's go to this project directory and I'm going to open
3:58 data and you can see I have three directories uh the directory called zero
4:04 another one called one another one called two and these are the three classes we are
4:10 going to generate we are going to classify today each one of these classes is encoded into a number into each one
4:15 of these numbers and if I open one of these directories you can see that this is me
4:21 just doing the exact process I just did just moving my camera towards the camera and away from the camera while I was
4:28 talking to you in this video so these are the samples these are the images I have just generated and for each one of
4:34 these directories I have 100 images right so I have collected 100 samples
4:40 from each category from each class I'm going to show you for the last class
4:47 which is exactly same idea but for the letter L so this is exactly a data we
4:53 are going to use in order to train or classifier and one of the things I want you to take from this video is that when
5:00 you are working on a computer vision project or actually any type of project when you are approaching a project when
5:06 you want to build a solution then there will be many many many many many many
5:11 many many different ways to build this solution there will be many different approaches you could take in order to
5:18 solve the problem that will be always the case given a problem there will be many many many
5:24 many many many possible solutions and the idea is that when you are just
5:29 sorting on a project the idea is that you consider some of these Solutions you just uh consider all the different ways
5:37 or some of the possible ways to solve the problem and then you decide for the most promising approach for the most
5:44 promising way right for example in this case one of the ways we could solve this
5:49 problem is by building an image classifier so if I open one of the frames for each category you
5:57 are going to see that let me do something like this one next to the
6:03 other so I can show you exactly what I mean one of the ways we could solve this
6:09 problem is by building an image classifier that takes the entire image
6:14 the entire frame as input and this image classifier to classify each one of these
6:20 frames into different categories so for example this image the entire image could be the letter A then this other
6:28 image will be the letter b and then this other image will be the letter L and so on right we could label the entire frame
6:36 with the category with the symbol we want to classify that will be a way to
6:41 do it that would be an approach then another approach will be to crop the image and to consider only the symbol we
6:50 want to detect right so for example in this case we will make this crop in this
6:55 other case we will make this over crop or something like it or something like this and then in this
7:02 whole case we will make this over crop right so in each case we will be using
7:08 the same approach in terms of using an image classifier but we will be classifying uh different things right or
7:16 we will be classifying only a curve from the entire frame so this will be another way to solve the problem and I think it
7:22 makes sense it will be a very a good way to solve the problem I'm sure we will achieve a very very high accuracy and
7:29 I'm sure we will achieve a perfect performance because it looks like a very good way to solve this volume but
7:36 another approach is to instead of using the entire image or instead of using an
7:43 image we could extract the information we care about this image which is only
7:48 the position of the hand right because if you realize for each one of these js2s or for each one of these symbols
7:55 all the information is in the position in the post sure of all the different
8:01 fingers and my hand and and so on right if you think about all the different symbols I show you when we started this
8:08 tutorial you will notice that all of these symbols the only difference between them or actually the information
8:14 in each one of these symbols is how the hand is located and how the fingers are
8:20 located and if you think about your fingers or if you think about a person's fingers there there are not many
8:28 situations or the movement we can do with our fingers is very constrained because we only have some possible
8:35 movements right so basically all the information in our hands it's in the
8:40 landmarks so if we use a landmark detector we will be extracting all the
8:46 information we care about these pictures these images and we will be
8:51 converting transform in each one of these images into a collection of points into something like 20 points or
8:59 something that I don't remember exactly how many landmarks are defined in the hand for the models we are going to use
9:05 today but it's something around 20 points so we will be taking an entire image of 640 times 480 pixels and we
9:16 will be reducing all that image which is actually a vgr image so it's this size
9:22 multiplied by three we will be taking this entire image and we will be transforming it into an array of
9:29 something like 20 points or 30 points or something in that so that's a very good
9:34 transformation because we are reducing the the space the input space the the
9:41 the data we are going to classify we are applying a dimensionality reduction technique because we are reducing the
9:46 dimensionality of our data while keeping the same information that's very important so that will be another
9:53 approach that will be another way to solve this problem and that's actually the way we are going to solve it that's
9:58 basically the classifier we are going to be building today so that's basically
10:03 something I think is very important I think it's one of the ways I want you to one of the things I want you to take from this video is that giving a problem
10:11 giving a project there are many many many many different ways to solve it and
10:16 it's very interesting and it's a very good exercise to consider all the different ways or some of the different
10:22 ways to solve it and to choose the most promising one that's one of the things I want you to
10:28 take from today's tutorial in this case we will we could classify the entire
10:33 image we will classify only a crop of the entire image or we could take the
10:39 landmarks of the hand in each one of these images and we just classify the landmarks and that's uh from my
10:46 perspective it's a much better approach because the classifier is going to be much
10:52 smaller and it will be much more robust as well because the input of this classifier will be the information it
10:59 needs in order to make a classification right it will be only the position of all the different fingers and the hand
11:04 and so on and we will be removing all the unnecessary information like all the pixels and the hand and the background
11:12 and me and everything else which is completely unnecessary in order to make the classification right so that's the
11:19 approach we are going to be taking today and this is the data in which we are going to be working into this tutorial
11:25 now in order to extract the landmarks and in order to move forward with the approach I described we are going to
11:32 take all the images and we are going to do some post processing we are going to process all these images so we create
11:38 exactly a data we need in order to train this classifier and the first thing I'm going to do is to import media pipe as
11:46 MP this is one of the libraries we are going to use then I'm also going to import CB2 cool
11:53 and I am going to import OS okay
12:00 and now what we are going to do is we are going to iterate in all the frames in all the images I show you a few
12:06 minutes ago and we are going to extract the landmarks from each one of these images and we are also going to save all
12:12 this data into a file we are later going to use in order to train or classifier
12:18 so let's start with that the data there I'm going to Define a variable which is
12:24 data there and this is targeted here okay then I am going to iterate in all
12:30 the directories in data there so this will be for during
12:36 foreign and I will
12:43 um iterate in all the frames Within These directory so this is something like a four image Parts in
12:53 all list here or part join data here
13:04 okay and and I'm going to Define this image but
13:12 as dot part join data dear dear and image part
13:21 and I'm going to create a variable which is image and image will be seeing a CV2
13:26 in read and this image part okay now I'm going to convert image into VAR or
13:33 actually into RGB it's already into bdr because we need to convert this image
13:39 into RGB in order to input the image into media pipe when we are working with
13:45 with media pipe all the landmark detection is always on RGB so as we are reading image in vgr we definitely need
13:52 to convert it into RGB so this will be CV to convert color
13:58 color [Music]
14:05 bgr2 RGB okay so this is pretty much all so this is
14:11 the images we are reading from our data directory and now I'm going to import
14:17 multiple live dot Pi plot because let's plot how these images look
14:24 like I am going to extract landmarks in a few minutes but for now let's just plot these images in order to make sure
14:29 everything is working properly so I'm just going to upload a few
14:34 I'm going to plot one for each directory so I am going to do something like this
14:42 so I only take the first one okay and now this is in show image RGB
14:51 remember that a metal Leaf also requires the image into RGB in order to plot this
14:57 image using battle leave this will be plot dot figure
15:04 and then plot.show and let's see what happens let's see if everything is working properly
15:13 okay perfect so we are plotting a frame from each class
15:18 from the three directories and everything seems to be working properly so far and now let me show you three
15:24 objects we are going to use which are these three sentences I have over here I'm just going to copy and paste
15:31 everything everything is already ready in this notepad so we don't really lose time defining these objects and this is
15:38 basically the three objects which are going to be super super useful in order to detect all the landmarks and in order
15:43 to draw these landmarks on top of the images we don't really need to draw the landmarks on top of the images in order
15:50 to do our classification but I'm going to to do it only to show you how these landmarks look like so these are the
15:56 three objects we are going to use and now let's define an object the hand
16:03 detector which is something like this this will be if I'm not mistaking a p
16:10 dot hands dot hands and then the variables are something
16:16 like study image mode true and then confidence mean detection
16:23 confidence which is we're going to use 0.3 okay so this is the model we are
16:29 going to use and now going back here remember this is the image this is the image we have converted into RGB and now
16:36 we are going to do something like this we're going to say hands.process and we're going to take this image here
16:43 and what we are doing here
16:48 is to detect all the landmarks into this image right that's exactly what we are
16:55 doing with this sentence and now the only thing we need to do is to iterate in the landmarks in all the landmarks we
17:02 have detected in this image and for that maybe the best way to do it in order to move one step at a time is to show you
17:08 how these landmarks look like so let me get back here and I am just going to
17:14 copy and paste this function which is going to be a much it's a much better
17:20 way to do it I'm just going to copy and paste it so we don't really lose time to coding this um
17:26 function from scratch so basically you can see that this is iterating in all
17:31 the results we have from this hand detection we are doing here because
17:38 remember we could be attacking only one hand or two hands or no hands at all so it makes perfect sense to iterate in all
17:45 the different results and then for each one of our results we are going to draw the landmarks and this is basically the
17:52 way to do it by calling these functions with this function with these arguments remember everything will be available in
17:58 the repository for today's tutorial so you can just take all the code from this repository and you can just take
18:05 everything from there from now for now just follow along so you should come follow the entire process and then you
18:12 can just go back to The Code by looking at the repository so this is the landmark drawing and this will be pretty
18:20 much all if I'm not mistaken let me just run this code to see what happens I have to do something else which is I need to
18:27 ask if we have detected at least
18:33 one hand right because we could be detecting no hand at all and that
18:41 that could be a problem for what we are going to do later on so let's just run
18:46 this script let's see what happens we are perfect just perfect you can see
18:54 that we are detecting exactly the position of the hand and we are just
19:00 detecting exactly all the different landmarks you can see that we have many different colors the style we are using
19:06 in order to the in order to draw these landmarks it's just it's giving us all these different colors so we know
19:12 exactly all the different fingers and so on so these are exactly the landmarks we
19:19 are going to use into this tutorial we are going to take all this information and we are going to
19:26 draw the we're going to build our classifier with this information so this is only to show you how these landmarks
19:32 look like and this is what I mean when I say that these landmarks contain absolutely all the information we need
19:38 in order to work on this tutorial in order to build this classifier because Take a Look only at the landmarks don't
19:45 take a look at the image itself at my hand but take a look only at the landmarks and you can see that all the
19:52 information we need it's in the landmarks right for example in this case for classifying the L we will need to
19:58 take a look what happens here what happens in this section with these four landmarks if we
20:06 have a situation like this where this finger it's like up and then all the other fingers are down then that's
20:13 pretty much all we need to know in order to make this classification and then if we go here if we notice these four
20:20 fingers are up this means we are in this situation and if we are in this sort of
20:25 situation with all the different fingers like this then we are here but absolutely all the information we
20:31 need is in the landmarks so it is only to show you how it looks like and it
20:36 will be exactly the same situation with absolutely any other symbol we choose the information will be in the landmarks
20:43 and now let's continue we don't really need to do the drawing the only reason I did the drawing was only to show you how
20:49 this looks like but we don't really need it so let's continue what we are going to do now is uh yeah I'm just going to
20:55 remove this part yeah because we don't really need I'm going to remove all the drawing I'm going to keep everything
21:02 else and what I'm going to do is I'm going to take the the entire landmarks
21:07 and I'm going to create an arrive from all the landmarks right I'm going to take all the image and from each image I
21:15 want to have an array with the information of absolutely all the landmarks we have detected right so in
21:22 order to go one step at a time I'm going to iterate for e in range uh the length of Handler marks.land mark
21:33 and I'm going to show you how these look like I am going to print this value and this is going to give us the value of
21:40 all the landmarks I'm going to show you how it looks like
21:45 first and then I'm going to do something with them
21:51 okay we don't really need to plot the images anymore but we have the images too and you can see that for each one of
21:57 these landmarks we have three values x y and sieve and these are all the values
22:04 which Define exactly the position of each one of our landmarks so we are
22:09 going to use only the X and the Y coordinates which are the horizontal and the vertical coordinates and from this
22:16 information we are going to create an array a very long array and we I think
22:22 we are going to train the classifier and we're going to inference this classifier by considering this array of landmarks
22:30 all on right so we have an image we detect the landmarks and then we take these landmarks into a very very long
22:36 array and that's there right we are going to consider in order to train our
22:41 classifier right that's a process we are taking and we are taking everything one
22:46 step at a time now we are going to access the X and the y coordinate so this will be the x coordinate and
22:54 then the y coordinate will be something like this
23:00 right and we are going to save everything into an array so I am going to create two variables which are data
23:08 and another one which is labels we don't really want to iterate in only
23:13 one image anymore so I'm going to delete that and I'm not going to plot it anymore
23:19 so we have defined these two variables which are the variables which are going to contain all the information right the
23:27 data which is the data we are going to produce in order to make this classification and then the labels which
23:33 are the category for each one of these images for each one of these data points
23:39 so this is how we're going to do it we are iterating in all the images
23:44 for each image I'm going to create an array which is data aux
23:50 and this is an empty array for now let me show you exactly what we are going to save here
23:55 this is where we are going to save the X and the Y coordinates
24:00 so
24:07 something like this X and then something like this with Y
24:12 right and then at the end of the entire iteration we are going to do something
24:18 like uh data dot append
24:24 data logs and then labels dot append
24:31 and then a deer which is the category right remember that we have three
24:38 categories we have three directories one of them is called zero the other one is called one and the other one is called two and each one of these directories
24:45 contains each one of our symbols so the symbol is encoded into the name of the
24:51 directory so this is exactly what we need to do for each one of our images we
24:56 are extracting all the landmarks we are creating a very long RPI with all these landmarks and then this very long array
25:04 is going to represent our image right we are going to create a an entire list
25:10 with all these different arise and then the labels will be the name of the
25:15 directory of each one of these images and doing so we are creating our data
25:21 set doing so we are creating the data set we need in order to train our classifier
25:26 and so that's pretty much all now let's see if this works properly because we have done many many different things and
25:34 there could be there are many places in which we could have made a mistake so
25:39 let's see what happens okay everything was successfully executed so everything seems to be okay
25:45 so what I'm going to do now is I'm going to save all this data so I'm going to do
25:51 something like this and I'm going to Define an object which is f and this is open
25:58 data dot pickle if I'm only saying I haven't imported pickles I'm going to
26:03 import it now and remember pickle is a python Library which is very commonly used for these type of situations to
26:10 save data to save data sets models and so on it's just like a way to save this
26:16 information so we are opening this file and we need to do it like this
26:24 okay because we are grating and it's also we are doing it as bytes so we need
26:29 to do it like this then we need to say pickle dot dump the object we are going to save and we
26:36 are going to create a dictionary containing these two keys
26:44 and here we will have the data and the labels we have just generated
26:49 and then we need to close the file and that's pretty much all and also we need
26:55 to input F here and that's pretty much all so let's see what happens I'm going to
27:03 run this again um and if everything runs successfully we
27:09 should have a file with this name okay everything runs successfully now if
27:15 I go to my directory I should see this file which is the file I have just
27:22 generated you can see this is my current time so this is if I did have just generated and I have other files from
27:29 all iterations or four executions where it was preparing this tutorial but this is the file they have just shared
27:35 so going back to poicharm so everything seems to be ready for now we have
27:42 created the data set this is the data we are going to use in order to train our classifier and now we can just continue
27:49 to The Next Step which is training this classifier now we are going to take the
27:54 data we are going to load this data and we're going to train a classifier with it so we are going to do exactly the
28:01 same as we are doing here but we are going to load the data instead so I am going to import pickle
28:10 is going to remove this string classifier and I am going to call
28:16 pickle.loa and this will be open the file name which is data dot pickle and
28:25 then I need to read this as RB okay and this will be our data
28:32 file or or data dictionary if I'm not mistaken this is the way to
28:39 read the data and now let's print let's print two things the keys of this
28:45 dictionary and let's also print the object data
28:51 sorry data dictionary and let's see what happens
28:58 okay everything seems to be okay these are all four labels and these are the
29:04 dictionary data these are the keys data and labels and then everything seems to
29:09 be working properly so now let's continue and let's continue by importing
29:15 all the different objects and all the different libraries we are going to use in order to train this classifier we are
29:21 going to train it using the library secret learn and we are going to use a very specific Model A very specific type
29:28 of classifier which is random Forest so let's start by importing from SQ
29:36 sklearn dot ensemble import random forest classifier and then
29:44 we're also going to import sqlarn dot model selection import train
29:52 test split and we're also going to import um from The Matrix Library
30:01 accuracy score okay so these are the three libraries we are going to use in this section in order to train this
30:07 classifier we are going to train a random forest classifier and these are two other functions we are going to need
30:13 two so let's start by and grabbing the data and the labels and this is how
30:18 we're going to do it and we're going to call that a dict and this will be
30:25 data and labels data dict
30:32 labels okay and we need to convert this into one ampere array
30:38 sorry I need to import an mp2 I'm going to do it just now
30:44 uh because we just need to import it
30:51 because this is the way this classifier works and this is why all these libraries work so I'm going to import
30:58 numpy SMP remember that currently or data is as a
31:05 list right data and labels are lists that's why we need to convert them into numpy arrays okay and the first thing we
31:13 need to do in order to train this classifier is to prepare the data so we have all four data into these two
31:20 objects data and labels now we are going to split this data into a training set
31:25 and a test set this is a very common practice when we are training a classifier any type of classifier we
31:32 usually need two sets assets we are going to use in order to train this algorithm and in another set we are
31:38 going to use in order to test the performance of this algorithm so this is what we are going to do and this is how
31:45 we're going to name this training set and this test set
31:50 um we're going to let me grade it first and I'm going to explain in a few minutes
31:55 this is something like this
32:02 this is where we're going to use this function uh we're going to input data labels
32:09 I'm just going to write everything down and I'm just going to explain it in a few minutes
32:15 um so just bear with me Shuffle it with true and then
32:22 stratify according to labels okay so what we are doing here is calling train
32:28 test split and we are splitting all of our data we are splitting all these
32:34 array and all this over array into two sets right so from the data list also
32:40 from the data array we are creating these two sets and you can see that one of them is called train and the other
32:46 one is called test and we're doing exactly the same for the labels we are creating two objects to arise one of
32:53 them is trained and the other one is test so we are taking all the information within data and labels and
33:00 we are splitting this information into two different sets let me find a picture so I can explain
33:09 this a little more so this will be a little more clear train test split I'm sure we're going to
33:15 have we're going to find many many different pictures explaining how this is done you can
33:22 consider this image so we have the entire a ride the entire day time and we
33:28 are splitting this data into two sets training set and test set so the
33:34 training set is what I have called xtrain and the test set is what I have called egg the X test that's basically
33:42 what we are doing and we are doing exactly the same process for data and labels then test size is the size of the
33:48 test set you can see that we have two sets and we can Define the size of this
33:54 test set for with different sizes right we could say this is a 10 of the data
34:00 the 20 the 50 the 80 and so on so I have specified this value in 0.2 which means
34:07 we are keeping the 20 percent of our data only the 20 percent as or test set
34:14 and 20 is a value which is very commonly used as a test
34:19 then Shuffle equal through means we are shuffling the data this is a very good
34:24 practice it's a very common practice and I will advise that you always always shuffle your data when you are doing
34:32 something like this when you are training a classifier because this is something I have mentioned I have
34:38 covered in our tutorials where I also show you how to train image classifiers or different type of classifiers and
34:45 sometimes there are different biases in our data that we are not aware of so
34:50 shuffling the data is a very common practice even when we think it's not
34:55 a long story short always remember to shuffle the data it's going to be much much further then stratify equals labels
35:03 this means that we are going to split it as a set but we are going to keep the
35:09 same proportion of the different labels of the different categories we had in this object we are going to keep exactly
35:16 the same proportion in the train set as in the test set right so this object and
35:23 this other object are going to have the same proportion of all of our different labels right so if you remember the data
35:32 we are using we have 100 elements in this category 100 elements in this or
35:38 category and 100 elements here so this means that one third of the data is
35:44 labeled as a which is this symbol one third of the data is B and one third is
35:51 L and if we look at these two objects white rain and white test we are going to see exactly same proportion one third
35:58 of all the data of all of the elements in these are I are going to be a then an
36:05 earth here will be a b and a North here with b l and exactly the same situation here so that's basically what it means
36:11 when we are stratifying according to the labels and that's also a very common practice and a very good practice when
36:17 we are splitting at asset so always remember to include stratify equals
36:23 labels when you're using trained test splits so this is all for splitting the
36:28 data and now it's time to create our model so the model we're going to use remember is a random Force classifier
36:36 so this is the classifier we are going to use and the first thing we need to do is to train this classifier so we are
36:44 going to call fit we're going to input X strain and white strain this is the way we are training this classifier this one
36:51 this is the way we are fitting this model and then we just need to call Dot
36:57 predict and we need to input X test and this will be y predict
37:04 and that's it in only a couple of lines we have
37:09 trained the classifier and we have also made our predictions this is how simple this is so let's just execute this
37:17 script to make sure everything works properly everything works properly and you may notice how fast it was right
37:24 this took only a few seconds if you are familiar with machine learning algorithms with training machine
37:30 learning algorithms you will know that sometimes it takes a lot of time to train a classifier but in this case this
37:37 is a very very fast training so that's one of the reasons I chose random 4 is
37:42 because it's like a very simple algorithm I know the training is very fast I know that it's robust enough for
37:48 or a problem for project so we have a really true in the classifier we have
37:54 all predictions and the only thing we need to do now is to see how these classifier performs so I am going to
38:03 find a new variable which is score and this will be accuracy score and I'm
38:08 going to input all predictions and then I'm going to input why tests which are all labels and now I
38:17 am going to print and this will be something like I'm
38:24 going to express it as a percentage of samples
38:31 were classified correctly
38:39 format and this is something like score something like this let's see what
38:45 percentage of our samples were classified correctly so I'm going to run
38:50 this code and you can see oh I forgot to do something which is multiplying this value times
38:59 100 you already saw the answer but anyway let's do it again 100 of our
39:06 samples were classified correctly so this is amazing this means we have a
39:12 perfect performance we have Trina classifier with a perfect performance so everything makes sense now the way we
39:19 process the data in order to extract all the landmarks for more images from our hands because that's where we had all
39:25 the information and now the selection we did for this classifier because we had
39:31 the intuition this is not really a super super complex problem and a random Forest will do just fine everything
39:37 makes sense now when we are achieving a 100 accuracy right so this is very good and
39:47 the only thing we're going to do now is to save this model the same way we save the data here we are going to save the
39:55 model because we want to use this model later on to to test the performance of
40:00 this model but not testing the performance as we did here but testing the performance of this model with real
40:07 data I am going to make some gestures some symbols and we are going to classify these symbols live on my camera
40:15 on this video so we definitely need the model I'm going to save this model like
40:20 model.pe and I'm going to do something similar I'm going to say model this will be
40:28 model on this okay so I am saving a dictionary
40:34 with only this object and I press play and that should be it we have to wait
40:40 and then it's it's completed if I go to my directory you can see the model we
40:46 have trained is here and this is my current time so everything it's okay
40:52 so everything is almost ready you only we have only one step left which is
40:57 testing this classifier so that's what we are going to do now okay now it's time to test our
41:04 classifier and the way we are going to test this classifier is by importing CV2
41:11 because we are going to access our webcam and we're here going to do all
41:16 these different symbols in our webcam and see what happens so cup will be something like CV2 video capture
41:24 and I'm going to access this webcam the number two and then while true
41:30 a cup dot read and this is red and frame
41:38 and then I am going to call CV2 IM show I'm going to call this window frame and
41:45 this will be my frame uh and then CB2 weight key
41:52 and here we should put a 25 which means we are going to wait 25 milliseconds
41:58 between each frame right so everything seems to be working fine and this is my
42:05 webcam so um what we are going to do now is we are going to detect uh all the landmarks in
42:13 this webcam we are going to detect all the landmarks of my hand and then we are going to use the classifier which is
42:18 trained in order to know what a symbol I am displaying in my hand so let's do that I am going to release memory I'm
42:26 not sure if it's reading here because we are exiting the program the the program anyway but I'm going to do it just just
42:33 because it's a good practice CV2 destroy all windows
42:38 and that's pretty much all so uh I don't have much space here
42:47 so let's go here and I'm going to copy a few
42:53 objects I'm going to copy this which is the
42:59 um the media pipe library or the media pipe functions we used
43:12 and then I am going to we also need the color conversion but
43:18 I'm going to do this okay something like this this will be frame
43:25 RGB frame frame RGB
43:31 and this is where we are going to um go through all the landmarks and
43:36 we're going to do something similar as we did before so I'm going to copy this
43:42 code I used before and the first thing we're going to do is to draw
43:47 the landmarks on top of the webcam and then we are going to classify it so as
43:53 always it's always a good idea to go one step at a time and let's just run this
43:59 code to see if everything works properly um everything seems to be working
44:05 properly you can see we are getting the landmarks from my hand and now it's the
44:11 time we are going to classify this object so we go back here and we say something
44:19 like this we are going to iterate in all the landmarks the same way we did before and now we are going to create a
44:29 no of an auxiliary array which is this
44:35 the same way we did before and the only thing we need to do now is
44:40 to um use the model but we need to read the model first we need to load the model
44:46 first so let's do something as we did before I'm just going to Define it here
44:54 let's say model dict is equal to pickle load mole dot p
45:03 and then let's say model equal to model dict
45:11 model and obviously I need to import pickle
45:17 okay and this should be enough now we are here yes we are here and we need to
45:25 um uh use model to predict the category so
45:31 let's see what happens this will be in p Us are right
45:37 from data Alex okay we need to import mp2
45:47 okay and let's see let's see what happens let's see if we don't get any
45:52 error okay we get an error of course and it's
46:00 related to the shape if I'm not mistaken what we need to do now is to input this
46:07 as a list let's see what happens now
46:15 yeah everything is okay so now we are using our classifier in order to classify the class for these landmarks
46:25 we are we have like a very like a more poor performance now now it's better it
46:31 seems the classification is not making this real time maybe if I do something like waiting only one millisecond
46:39 it's not like it's the most important thing but just so we can have like a more real-time detection now it's a
46:46 little better remember I'm also recording my screen so that takes resources that's pretty much the reason
46:52 I think so let's continue everything seems to be working properly and what we will do now
47:00 now that we have our our prediction this is our prediction
47:06 we are going to draw the prediction on top of our frame or actually what we can
47:12 do we can define a dictionary which is something like labels digged and this is
47:22 0 equal to a remember the number zero represents the a character then one
47:29 represents B and then two
47:34 sorry I'm doing things wrong and two represents l
47:43 okay and what I can do now
47:48 [Music] um something like predicted
47:54 character it's equal to
48:00 um labels digged int prediction
48:07 zero because we are getting a list prediction is a list of only one element
48:13 so we need to do it this way okay that's pretty much all let's print
48:20 predict this character I'm super excited let's see if this works I'm super
48:26 excited so I press play and now let's see if we can accurately detect and
48:33 recognize all the symbols we have just trained so the first one is the ah I
48:38 have to put my run again and if I do the a character you can see
48:45 I'm getting a once and again I'm getting a so everything seems to be working properly now I'm doing the B and you can
48:52 see I'm doing I'm getting B once and again I'm getting B and everything goes perfect and if I do L which is this
49:00 value you can see I'm getting the L and also the accuracy it's perfect so that's
49:05 pretty much all because it seems everything is working super super properly the only thing we're going to do now is to make a more pretty drawing
49:13 right let's just print the um the prediction on top of the frame and let's
49:18 do also like a bounding box around the prediction around the hand we already
49:23 take things so that's what we are going to do now but you can see that we have solved the problem we have completed all
49:30 the different steps we have train the classifier and now we are testing the classifier and everything seems perfect
49:35 we are testing this classifier with live data and everything seems perfect so the
49:41 only thing we're going to do now is to do called rectangle and we are going to input frame
49:49 and then we're going to input a two values which are X1
49:58 and X2 and then we're also going to input sorry this is y1 and this is X2 Y2
50:09 a color which I'm going to Define in Black because we have too many colors right
50:14 ready in this picture in this frame with all the landmarks and so on so I'm just going to set it in Black
50:20 and then the thickness value which will be I don't know four something before
50:26 and I'm just going to do this now and I'm going to [Music] um
50:33 I'm going to Define X1 and X when y1 and X2 and Y2 in a minute but let's just
50:40 continue for now and I I want to call put text and I have a pulled text here so I'm just going to copy paste and I'm
50:47 going to [Music] um edit it with these values
50:53 this is going to be the class we already take it in so it's exactly this
51:01 then this will be here remember we have solved this problem so
51:08 we should be super super happy this is only a detail to make a very pretty drawing but everything is sold
51:15 everything is perfect so we are drawing a rectangle and we also put in the text on top of this rectangle with the class
51:22 we are predicting and now we have to Define these values in order to find these values the way
51:28 I'm going to do it I'm going to Define two additional arise
51:33 which is here X and Y I think this will be the easiest way to
51:40 solve this problem so I'm just I have defined these two auxiliary arise and
51:45 I'm going to say x dot append X and then y dot append and Y
51:54 and I'm going to say something like X1 equal to
52:01 the minimum value of x yes
52:09 then y1 is exactly the same for y and
52:15 then X2 and Y2 are the maximums
52:22 remember we are trying to get the corners of the rectangle contained in the hand
52:29 and we're also um so we know exactly where to display this rectangle and this text so this
52:36 should do but we need to do something else because if you remember the values
52:42 we were getting for the landmarks everything is in a in a float everything is float so we need to convert it into
52:49 an integer and the way we're going to do it is by calling uh we are going to get the frame shape
52:59 everything's okay and then we are just going to multiply this value times the
53:05 width of our image and we are multiplying the solar value
53:10 times the height uh we need to cast everything as an
53:16 integer and this should be enough
53:22 let's see how it performs this is not necessary
53:29 and and okay okay let's see let's see if it works or
53:36 or if we need to adjust something else okay X1 is not defined okay so the
53:42 problem is that if we are not detecting any hands right if the if there's not any hand in the frame then we never
53:49 execute this Loop we never Define these variables and we cannot draw the rectangle Lambda text in the location we
53:56 specify so doing something this should be enough now let's execute it again and
54:01 I'm just going to do an a and you can see that I'm classifying the
54:07 a super super properly now I'm going to do a b and now I am going to do an l and
54:13 everything is okay I'm going to adjust a very very small detail which is I am
54:18 going to do this drawing in a slightly different position I have already been testing different values and if I do it
54:25 here in -10 everything is going to look much much nicer and I'm going to do this in y1
54:33 -10 if I'm not mistaken sorry sorry sorry I'm a mistake it's the older one
54:38 the text one y1 minus 10 if I execute it again
54:45 everything is going to look a little nicer so they say you can see now we are seeing the A on top of the bounding box
54:52 this is B and this is L so everything is working super super purpley and that's
54:59 going to be all for this tutorial so let's go into your for today my name is Philippe I'm a computer vision engineer
55:05 if you enjoyed this video I invite you to click the like button and I also invite you to subscribe to my channel in
55:11 this channel I usually make tutorials cooling tutorials which are exactly like this one and I also share my experience
55:18 as a computer vision engineer so if these are the type of videos you're into I invite you and you're super super
55:24 welcome to subscribe to my channel this is going to be your for today and see you on the next video
55:33 [Music]
0:00 so this is exactly a project in which we will be working today you can see that this is a sign language detector we are
0:06 currently detecting different signs I am doing with my hands these are three signs I have selected from the American
0:11 sign language alphabet from this alphabet I have over here I have selected the letter A the letter b and
0:17 the letter L but obviously we could apply exactly the same process to absolutely any other symbol absolutely
0:24 any other sign from this alphabet or from any other sign language alphabet from any other country so this is
0:30 exactly a project in which we will be working on today's tutorial this will be 100 in Python we are going to be using
0:37 opencv media pipe we are going to be addicting the landmarks from our hands so this is going to be an amazing
0:42 tutorial and let's get started so this is exactly the project in which we are going to be working today and now let me
0:49 show you the pycharm project I created for today's tutorial we are going to work with these three requirements
0:56 obviously please remember to install these requirements before starting with this tutorial we are going to work with
1:01 opencv media pipe this is a very important Library we are going to use today and we're also going to work with
1:06 ckit learn so these are the requirements for today's tutorial and now let me tell
1:12 you about the project about the processing which we are going to be working today this will be a three steps
1:18 process and this is actually a very classical machine learning process we are going to start with the data
1:24 preparation the data creation then we're going to train the model and then we're going to test how this model performs so
1:31 these are the three steps in which we are going to be working today now in order to get started with this
1:37 tutorial I have already created a script which is going to be super super helpful in order to create our data set this is
1:44 a script I have already created so we can save some time while we are working
1:49 onto this tutorial so we can focus our energy on everything else because everything else will be much much more
1:55 important so you can see that this is my webcam and I have a message on my webcam saying ready and if ready press the
2:02 letter Q so the way we are going to use this script the way we are going to use this uh webcam is that we are going to
2:10 collect many different samples of the three symbols I shall show you right so
2:16 what I'm going to do is for example for the letter A for this symbol which represent the letter A I'm going to do
2:21 many times I'm going to do this process I'm going to move my hand towards the
2:26 camera and away from the camera and this way what I'm going to do is to create many different samples many different
2:33 examples of how the leather a it looks like right remember we are building a
2:39 classifier and the way classifiers work classifiers need data and the more data
2:44 we have or the more diverse data we have is going to be much better so I am going to do this this process
2:50 for the letter A then I'm going to repeat the same process for the letter b and then I'm going to do exactly the
2:55 same process for the letter L so we are going to repeat this process for these three symbols and this way we are going
3:01 to collect our data we are going to generate our data set that we are going
3:07 to create in order to work on today's tutorial so the idea is that once I'm ready I press the letter q and I start
3:13 collecting symbols I start collecting frames for all these different symbols so let's start there I'm going to press
3:19 the letter q and I'm going to move my hand towards the camera and away from the camera
3:25 and that's it so now I'm going to move to the next symbol which is something
3:31 this and I'm going to move my hand towards the camera and away from the camera
3:36 and I'm going to look for a few seconds and that's pretty much all I'm going to do the same with the letter L and I'm
3:44 going to move my hand towards the camera and away from the camera and I'm going to show you in a few
3:50 seconds how this data looks like so this is pretty much all now let's go to this project directory and I'm going to open
3:58 data and you can see I have three directories uh the directory called zero
4:04 another one called one another one called two and these are the three classes we are
4:10 going to generate we are going to classify today each one of these classes is encoded into a number into each one
4:15 of these numbers and if I open one of these directories you can see that this is me
4:21 just doing the exact process I just did just moving my camera towards the camera and away from the camera while I was
4:28 talking to you in this video so these are the samples these are the images I have just generated and for each one of
4:34 these directories I have 100 images right so I have collected 100 samples
4:40 from each category from each class I'm going to show you for the last class
4:47 which is exactly same idea but for the letter L so this is exactly a data we
4:53 are going to use in order to train or classifier and one of the things I want you to take from this video is that when
5:00 you are working on a computer vision project or actually any type of project when you are approaching a project when
5:06 you want to build a solution then there will be many many many many many many
5:11 many many different ways to build this solution there will be many different approaches you could take in order to
5:18 solve the problem that will be always the case given a problem there will be many many many
5:24 many many many possible solutions and the idea is that when you are just
5:29 sorting on a project the idea is that you consider some of these Solutions you just uh consider all the different ways
5:37 or some of the possible ways to solve the problem and then you decide for the most promising approach for the most
5:44 promising way right for example in this case one of the ways we could solve this
5:49 problem is by building an image classifier so if I open one of the frames for each category you
5:57 are going to see that let me do something like this one next to the
6:03 other so I can show you exactly what I mean one of the ways we could solve this
6:09 problem is by building an image classifier that takes the entire image
6:14 the entire frame as input and this image classifier to classify each one of these
6:20 frames into different categories so for example this image the entire image could be the letter A then this other
6:28 image will be the letter b and then this other image will be the letter L and so on right we could label the entire frame
6:36 with the category with the symbol we want to classify that will be a way to
6:41 do it that would be an approach then another approach will be to crop the image and to consider only the symbol we
6:50 want to detect right so for example in this case we will make this crop in this
6:55 other case we will make this over crop or something like it or something like this and then in this
7:02 whole case we will make this over crop right so in each case we will be using
7:08 the same approach in terms of using an image classifier but we will be classifying uh different things right or
7:16 we will be classifying only a curve from the entire frame so this will be another way to solve the problem and I think it
7:22 makes sense it will be a very a good way to solve the problem I'm sure we will achieve a very very high accuracy and
7:29 I'm sure we will achieve a perfect performance because it looks like a very good way to solve this volume but
7:36 another approach is to instead of using the entire image or instead of using an
7:43 image we could extract the information we care about this image which is only
7:48 the position of the hand right because if you realize for each one of these js2s or for each one of these symbols
7:55 all the information is in the position in the post sure of all the different
8:01 fingers and my hand and and so on right if you think about all the different symbols I show you when we started this
8:08 tutorial you will notice that all of these symbols the only difference between them or actually the information
8:14 in each one of these symbols is how the hand is located and how the fingers are
8:20 located and if you think about your fingers or if you think about a person's fingers there there are not many
8:28 situations or the movement we can do with our fingers is very constrained because we only have some possible
8:35 movements right so basically all the information in our hands it's in the
8:40 landmarks so if we use a landmark detector we will be extracting all the
8:46 information we care about these pictures these images and we will be
8:51 converting transform in each one of these images into a collection of points into something like 20 points or
8:59 something that I don't remember exactly how many landmarks are defined in the hand for the models we are going to use
9:05 today but it's something around 20 points so we will be taking an entire image of 640 times 480 pixels and we
9:16 will be reducing all that image which is actually a vgr image so it's this size
9:22 multiplied by three we will be taking this entire image and we will be transforming it into an array of
9:29 something like 20 points or 30 points or something in that so that's a very good
9:34 transformation because we are reducing the the space the input space the the
9:41 the data we are going to classify we are applying a dimensionality reduction technique because we are reducing the
9:46 dimensionality of our data while keeping the same information that's very important so that will be another
9:53 approach that will be another way to solve this problem and that's actually the way we are going to solve it that's
9:58 basically the classifier we are going to be building today so that's basically
10:03 something I think is very important I think it's one of the ways I want you to one of the things I want you to take from this video is that giving a problem
10:11 giving a project there are many many many many different ways to solve it and
10:16 it's very interesting and it's a very good exercise to consider all the different ways or some of the different
10:22 ways to solve it and to choose the most promising one that's one of the things I want you to
10:28 take from today's tutorial in this case we will we could classify the entire
10:33 image we will classify only a crop of the entire image or we could take the
10:39 landmarks of the hand in each one of these images and we just classify the landmarks and that's uh from my
10:46 perspective it's a much better approach because the classifier is going to be much
10:52 smaller and it will be much more robust as well because the input of this classifier will be the information it
10:59 needs in order to make a classification right it will be only the position of all the different fingers and the hand
11:04 and so on and we will be removing all the unnecessary information like all the pixels and the hand and the background
11:12 and me and everything else which is completely unnecessary in order to make the classification right so that's the
11:19 approach we are going to be taking today and this is the data in which we are going to be working into this tutorial
11:25 now in order to extract the landmarks and in order to move forward with the approach I described we are going to
11:32 take all the images and we are going to do some post processing we are going to process all these images so we create
11:38 exactly a data we need in order to train this classifier and the first thing I'm going to do is to import media pipe as
11:46 MP this is one of the libraries we are going to use then I'm also going to import CB2 cool
11:53 and I am going to import OS okay
12:00 and now what we are going to do is we are going to iterate in all the frames in all the images I show you a few
12:06 minutes ago and we are going to extract the landmarks from each one of these images and we are also going to save all
12:12 this data into a file we are later going to use in order to train or classifier
12:18 so let's start with that the data there I'm going to Define a variable which is
12:24 data there and this is targeted here okay then I am going to iterate in all
12:30 the directories in data there so this will be for during
12:36 foreign and I will
12:43 um iterate in all the frames Within These directory so this is something like a four image Parts in
12:53 all list here or part join data here
13:04 okay and and I'm going to Define this image but
13:12 as dot part join data dear dear and image part
13:21 and I'm going to create a variable which is image and image will be seeing a CV2
13:26 in read and this image part okay now I'm going to convert image into VAR or
13:33 actually into RGB it's already into bdr because we need to convert this image
13:39 into RGB in order to input the image into media pipe when we are working with
13:45 with media pipe all the landmark detection is always on RGB so as we are reading image in vgr we definitely need
13:52 to convert it into RGB so this will be CV to convert color
13:58 color [Music]
14:05 bgr2 RGB okay so this is pretty much all so this is
14:11 the images we are reading from our data directory and now I'm going to import
14:17 multiple live dot Pi plot because let's plot how these images look
14:24 like I am going to extract landmarks in a few minutes but for now let's just plot these images in order to make sure
14:29 everything is working properly so I'm just going to upload a few
14:34 I'm going to plot one for each directory so I am going to do something like this
14:42 so I only take the first one okay and now this is in show image RGB
14:51 remember that a metal Leaf also requires the image into RGB in order to plot this
14:57 image using battle leave this will be plot dot figure
15:04 and then plot.show and let's see what happens let's see if everything is working properly
15:13 okay perfect so we are plotting a frame from each class
15:18 from the three directories and everything seems to be working properly so far and now let me show you three
15:24 objects we are going to use which are these three sentences I have over here I'm just going to copy and paste
15:31 everything everything is already ready in this notepad so we don't really lose time defining these objects and this is
15:38 basically the three objects which are going to be super super useful in order to detect all the landmarks and in order
15:43 to draw these landmarks on top of the images we don't really need to draw the landmarks on top of the images in order
15:50 to do our classification but I'm going to to do it only to show you how these landmarks look like so these are the
15:56 three objects we are going to use and now let's define an object the hand
16:03 detector which is something like this this will be if I'm not mistaking a p
16:10 dot hands dot hands and then the variables are something
16:16 like study image mode true and then confidence mean detection
16:23 confidence which is we're going to use 0.3 okay so this is the model we are
16:29 going to use and now going back here remember this is the image this is the image we have converted into RGB and now
16:36 we are going to do something like this we're going to say hands.process and we're going to take this image here
16:43 and what we are doing here
16:48 is to detect all the landmarks into this image right that's exactly what we are
16:55 doing with this sentence and now the only thing we need to do is to iterate in the landmarks in all the landmarks we
17:02 have detected in this image and for that maybe the best way to do it in order to move one step at a time is to show you
17:08 how these landmarks look like so let me get back here and I am just going to
17:14 copy and paste this function which is going to be a much it's a much better
17:20 way to do it I'm just going to copy and paste it so we don't really lose time to coding this um
17:26 function from scratch so basically you can see that this is iterating in all
17:31 the results we have from this hand detection we are doing here because
17:38 remember we could be attacking only one hand or two hands or no hands at all so it makes perfect sense to iterate in all
17:45 the different results and then for each one of our results we are going to draw the landmarks and this is basically the
17:52 way to do it by calling these functions with this function with these arguments remember everything will be available in
17:58 the repository for today's tutorial so you can just take all the code from this repository and you can just take
18:05 everything from there from now for now just follow along so you should come follow the entire process and then you
18:12 can just go back to The Code by looking at the repository so this is the landmark drawing and this will be pretty
18:20 much all if I'm not mistaken let me just run this code to see what happens I have to do something else which is I need to
18:27 ask if we have detected at least
18:33 one hand right because we could be detecting no hand at all and that
18:41 that could be a problem for what we are going to do later on so let's just run
18:46 this script let's see what happens we are perfect just perfect you can see
18:54 that we are detecting exactly the position of the hand and we are just
19:00 detecting exactly all the different landmarks you can see that we have many different colors the style we are using
19:06 in order to the in order to draw these landmarks it's just it's giving us all these different colors so we know
19:12 exactly all the different fingers and so on so these are exactly the landmarks we
19:19 are going to use into this tutorial we are going to take all this information and we are going to
19:26 draw the we're going to build our classifier with this information so this is only to show you how these landmarks
19:32 look like and this is what I mean when I say that these landmarks contain absolutely all the information we need
19:38 in order to work on this tutorial in order to build this classifier because Take a Look only at the landmarks don't
19:45 take a look at the image itself at my hand but take a look only at the landmarks and you can see that all the
19:52 information we need it's in the landmarks right for example in this case for classifying the L we will need to
19:58 take a look what happens here what happens in this section with these four landmarks if we
20:06 have a situation like this where this finger it's like up and then all the other fingers are down then that's
20:13 pretty much all we need to know in order to make this classification and then if we go here if we notice these four
20:20 fingers are up this means we are in this situation and if we are in this sort of
20:25 situation with all the different fingers like this then we are here but absolutely all the information we
20:31 need is in the landmarks so it is only to show you how it looks like and it
20:36 will be exactly the same situation with absolutely any other symbol we choose the information will be in the landmarks
20:43 and now let's continue we don't really need to do the drawing the only reason I did the drawing was only to show you how
20:49 this looks like but we don't really need it so let's continue what we are going to do now is uh yeah I'm just going to
20:55 remove this part yeah because we don't really need I'm going to remove all the drawing I'm going to keep everything
21:02 else and what I'm going to do is I'm going to take the the entire landmarks
21:07 and I'm going to create an arrive from all the landmarks right I'm going to take all the image and from each image I
21:15 want to have an array with the information of absolutely all the landmarks we have detected right so in
21:22 order to go one step at a time I'm going to iterate for e in range uh the length of Handler marks.land mark
21:33 and I'm going to show you how these look like I am going to print this value and this is going to give us the value of
21:40 all the landmarks I'm going to show you how it looks like
21:45 first and then I'm going to do something with them
21:51 okay we don't really need to plot the images anymore but we have the images too and you can see that for each one of
21:57 these landmarks we have three values x y and sieve and these are all the values
22:04 which Define exactly the position of each one of our landmarks so we are
22:09 going to use only the X and the Y coordinates which are the horizontal and the vertical coordinates and from this
22:16 information we are going to create an array a very long array and we I think
22:22 we are going to train the classifier and we're going to inference this classifier by considering this array of landmarks
22:30 all on right so we have an image we detect the landmarks and then we take these landmarks into a very very long
22:36 array and that's there right we are going to consider in order to train our
22:41 classifier right that's a process we are taking and we are taking everything one
22:46 step at a time now we are going to access the X and the y coordinate so this will be the x coordinate and
22:54 then the y coordinate will be something like this
23:00 right and we are going to save everything into an array so I am going to create two variables which are data
23:08 and another one which is labels we don't really want to iterate in only
23:13 one image anymore so I'm going to delete that and I'm not going to plot it anymore
23:19 so we have defined these two variables which are the variables which are going to contain all the information right the
23:27 data which is the data we are going to produce in order to make this classification and then the labels which
23:33 are the category for each one of these images for each one of these data points
23:39 so this is how we're going to do it we are iterating in all the images
23:44 for each image I'm going to create an array which is data aux
23:50 and this is an empty array for now let me show you exactly what we are going to save here
23:55 this is where we are going to save the X and the Y coordinates
24:00 so
24:07 something like this X and then something like this with Y
24:12 right and then at the end of the entire iteration we are going to do something
24:18 like uh data dot append
24:24 data logs and then labels dot append
24:31 and then a deer which is the category right remember that we have three
24:38 categories we have three directories one of them is called zero the other one is called one and the other one is called two and each one of these directories
24:45 contains each one of our symbols so the symbol is encoded into the name of the
24:51 directory so this is exactly what we need to do for each one of our images we
24:56 are extracting all the landmarks we are creating a very long RPI with all these landmarks and then this very long array
25:04 is going to represent our image right we are going to create a an entire list
25:10 with all these different arise and then the labels will be the name of the
25:15 directory of each one of these images and doing so we are creating our data
25:21 set doing so we are creating the data set we need in order to train our classifier
25:26 and so that's pretty much all now let's see if this works properly because we have done many many different things and
25:34 there could be there are many places in which we could have made a mistake so
25:39 let's see what happens okay everything was successfully executed so everything seems to be okay
25:45 so what I'm going to do now is I'm going to save all this data so I'm going to do
25:51 something like this and I'm going to Define an object which is f and this is open
25:58 data dot pickle if I'm only saying I haven't imported pickles I'm going to
26:03 import it now and remember pickle is a python Library which is very commonly used for these type of situations to
26:10 save data to save data sets models and so on it's just like a way to save this
26:16 information so we are opening this file and we need to do it like this
26:24 okay because we are grating and it's also we are doing it as bytes so we need
26:29 to do it like this then we need to say pickle dot dump the object we are going to save and we
26:36 are going to create a dictionary containing these two keys
26:44 and here we will have the data and the labels we have just generated
26:49 and then we need to close the file and that's pretty much all and also we need
26:55 to input F here and that's pretty much all so let's see what happens I'm going to
27:03 run this again um and if everything runs successfully we
27:09 should have a file with this name okay everything runs successfully now if
27:15 I go to my directory I should see this file which is the file I have just
27:22 generated you can see this is my current time so this is if I did have just generated and I have other files from
27:29 all iterations or four executions where it was preparing this tutorial but this is the file they have just shared
27:35 so going back to poicharm so everything seems to be ready for now we have
27:42 created the data set this is the data we are going to use in order to train our classifier and now we can just continue
27:49 to The Next Step which is training this classifier now we are going to take the
27:54 data we are going to load this data and we're going to train a classifier with it so we are going to do exactly the
28:01 same as we are doing here but we are going to load the data instead so I am going to import pickle
28:10 is going to remove this string classifier and I am going to call
28:16 pickle.loa and this will be open the file name which is data dot pickle and
28:25 then I need to read this as RB okay and this will be our data
28:32 file or or data dictionary if I'm not mistaken this is the way to
28:39 read the data and now let's print let's print two things the keys of this
28:45 dictionary and let's also print the object data
28:51 sorry data dictionary and let's see what happens
28:58 okay everything seems to be okay these are all four labels and these are the
29:04 dictionary data these are the keys data and labels and then everything seems to
29:09 be working properly so now let's continue and let's continue by importing
29:15 all the different objects and all the different libraries we are going to use in order to train this classifier we are
29:21 going to train it using the library secret learn and we are going to use a very specific Model A very specific type
29:28 of classifier which is random Forest so let's start by importing from SQ
29:36 sklearn dot ensemble import random forest classifier and then
29:44 we're also going to import sqlarn dot model selection import train
29:52 test split and we're also going to import um from The Matrix Library
30:01 accuracy score okay so these are the three libraries we are going to use in this section in order to train this
30:07 classifier we are going to train a random forest classifier and these are two other functions we are going to need
30:13 two so let's start by and grabbing the data and the labels and this is how
30:18 we're going to do it and we're going to call that a dict and this will be
30:25 data and labels data dict
30:32 labels okay and we need to convert this into one ampere array
30:38 sorry I need to import an mp2 I'm going to do it just now
30:44 uh because we just need to import it
30:51 because this is the way this classifier works and this is why all these libraries work so I'm going to import
30:58 numpy SMP remember that currently or data is as a
31:05 list right data and labels are lists that's why we need to convert them into numpy arrays okay and the first thing we
31:13 need to do in order to train this classifier is to prepare the data so we have all four data into these two
31:20 objects data and labels now we are going to split this data into a training set
31:25 and a test set this is a very common practice when we are training a classifier any type of classifier we
31:32 usually need two sets assets we are going to use in order to train this algorithm and in another set we are
31:38 going to use in order to test the performance of this algorithm so this is what we are going to do and this is how
31:45 we're going to name this training set and this test set
31:50 um we're going to let me grade it first and I'm going to explain in a few minutes
31:55 this is something like this
32:02 this is where we're going to use this function uh we're going to input data labels
32:09 I'm just going to write everything down and I'm just going to explain it in a few minutes
32:15 um so just bear with me Shuffle it with true and then
32:22 stratify according to labels okay so what we are doing here is calling train
32:28 test split and we are splitting all of our data we are splitting all these
32:34 array and all this over array into two sets right so from the data list also
32:40 from the data array we are creating these two sets and you can see that one of them is called train and the other
32:46 one is called test and we're doing exactly the same for the labels we are creating two objects to arise one of
32:53 them is trained and the other one is test so we are taking all the information within data and labels and
33:00 we are splitting this information into two different sets let me find a picture so I can explain
33:09 this a little more so this will be a little more clear train test split I'm sure we're going to
33:15 have we're going to find many many different pictures explaining how this is done you can
33:22 consider this image so we have the entire a ride the entire day time and we
33:28 are splitting this data into two sets training set and test set so the
33:34 training set is what I have called xtrain and the test set is what I have called egg the X test that's basically
33:42 what we are doing and we are doing exactly the same process for data and labels then test size is the size of the
33:48 test set you can see that we have two sets and we can Define the size of this
33:54 test set for with different sizes right we could say this is a 10 of the data
34:00 the 20 the 50 the 80 and so on so I have specified this value in 0.2 which means
34:07 we are keeping the 20 percent of our data only the 20 percent as or test set
34:14 and 20 is a value which is very commonly used as a test
34:19 then Shuffle equal through means we are shuffling the data this is a very good
34:24 practice it's a very common practice and I will advise that you always always shuffle your data when you are doing
34:32 something like this when you are training a classifier because this is something I have mentioned I have
34:38 covered in our tutorials where I also show you how to train image classifiers or different type of classifiers and
34:45 sometimes there are different biases in our data that we are not aware of so
34:50 shuffling the data is a very common practice even when we think it's not
34:55 a long story short always remember to shuffle the data it's going to be much much further then stratify equals labels
35:03 this means that we are going to split it as a set but we are going to keep the
35:09 same proportion of the different labels of the different categories we had in this object we are going to keep exactly
35:16 the same proportion in the train set as in the test set right so this object and
35:23 this other object are going to have the same proportion of all of our different labels right so if you remember the data
35:32 we are using we have 100 elements in this category 100 elements in this or
35:38 category and 100 elements here so this means that one third of the data is
35:44 labeled as a which is this symbol one third of the data is B and one third is
35:51 L and if we look at these two objects white rain and white test we are going to see exactly same proportion one third
35:58 of all the data of all of the elements in these are I are going to be a then an
36:05 earth here will be a b and a North here with b l and exactly the same situation here so that's basically what it means
36:11 when we are stratifying according to the labels and that's also a very common practice and a very good practice when
36:17 we are splitting at asset so always remember to include stratify equals
36:23 labels when you're using trained test splits so this is all for splitting the
36:28 data and now it's time to create our model so the model we're going to use remember is a random Force classifier
36:36 so this is the classifier we are going to use and the first thing we need to do is to train this classifier so we are
36:44 going to call fit we're going to input X strain and white strain this is the way we are training this classifier this one
36:51 this is the way we are fitting this model and then we just need to call Dot
36:57 predict and we need to input X test and this will be y predict
37:04 and that's it in only a couple of lines we have
37:09 trained the classifier and we have also made our predictions this is how simple this is so let's just execute this
37:17 script to make sure everything works properly everything works properly and you may notice how fast it was right
37:24 this took only a few seconds if you are familiar with machine learning algorithms with training machine
37:30 learning algorithms you will know that sometimes it takes a lot of time to train a classifier but in this case this
37:37 is a very very fast training so that's one of the reasons I chose random 4 is
37:42 because it's like a very simple algorithm I know the training is very fast I know that it's robust enough for
37:48 or a problem for project so we have a really true in the classifier we have
37:54 all predictions and the only thing we need to do now is to see how these classifier performs so I am going to
38:03 find a new variable which is score and this will be accuracy score and I'm
38:08 going to input all predictions and then I'm going to input why tests which are all labels and now I
38:17 am going to print and this will be something like I'm
38:24 going to express it as a percentage of samples
38:31 were classified correctly
38:39 format and this is something like score something like this let's see what
38:45 percentage of our samples were classified correctly so I'm going to run
38:50 this code and you can see oh I forgot to do something which is multiplying this value times
38:59 100 you already saw the answer but anyway let's do it again 100 of our
39:06 samples were classified correctly so this is amazing this means we have a
39:12 perfect performance we have Trina classifier with a perfect performance so everything makes sense now the way we
39:19 process the data in order to extract all the landmarks for more images from our hands because that's where we had all
39:25 the information and now the selection we did for this classifier because we had
39:31 the intuition this is not really a super super complex problem and a random Forest will do just fine everything
39:37 makes sense now when we are achieving a 100 accuracy right so this is very good and
39:47 the only thing we're going to do now is to save this model the same way we save the data here we are going to save the
39:55 model because we want to use this model later on to to test the performance of
40:00 this model but not testing the performance as we did here but testing the performance of this model with real
40:07 data I am going to make some gestures some symbols and we are going to classify these symbols live on my camera
40:15 on this video so we definitely need the model I'm going to save this model like
40:20 model.pe and I'm going to do something similar I'm going to say model this will be
40:28 model on this okay so I am saving a dictionary
40:34 with only this object and I press play and that should be it we have to wait
40:40 and then it's it's completed if I go to my directory you can see the model we
40:46 have trained is here and this is my current time so everything it's okay
40:52 so everything is almost ready you only we have only one step left which is
40:57 testing this classifier so that's what we are going to do now okay now it's time to test our
41:04 classifier and the way we are going to test this classifier is by importing CV2
41:11 because we are going to access our webcam and we're here going to do all
41:16 these different symbols in our webcam and see what happens so cup will be something like CV2 video capture
41:24 and I'm going to access this webcam the number two and then while true
41:30 a cup dot read and this is red and frame
41:38 and then I am going to call CV2 IM show I'm going to call this window frame and
41:45 this will be my frame uh and then CB2 weight key
41:52 and here we should put a 25 which means we are going to wait 25 milliseconds
41:58 between each frame right so everything seems to be working fine and this is my
42:05 webcam so um what we are going to do now is we are going to detect uh all the landmarks in
42:13 this webcam we are going to detect all the landmarks of my hand and then we are going to use the classifier which is
42:18 trained in order to know what a symbol I am displaying in my hand so let's do that I am going to release memory I'm
42:26 not sure if it's reading here because we are exiting the program the the program anyway but I'm going to do it just just
42:33 because it's a good practice CV2 destroy all windows
42:38 and that's pretty much all so uh I don't have much space here
42:47 so let's go here and I'm going to copy a few
42:53 objects I'm going to copy this which is the
42:59 um the media pipe library or the media pipe functions we used
43:12 and then I am going to we also need the color conversion but
43:18 I'm going to do this okay something like this this will be frame
43:25 RGB frame frame RGB
43:31 and this is where we are going to um go through all the landmarks and
43:36 we're going to do something similar as we did before so I'm going to copy this
43:42 code I used before and the first thing we're going to do is to draw
43:47 the landmarks on top of the webcam and then we are going to classify it so as
43:53 always it's always a good idea to go one step at a time and let's just run this
43:59 code to see if everything works properly um everything seems to be working
44:05 properly you can see we are getting the landmarks from my hand and now it's the
44:11 time we are going to classify this object so we go back here and we say something
44:19 like this we are going to iterate in all the landmarks the same way we did before and now we are going to create a
44:29 no of an auxiliary array which is this
44:35 the same way we did before and the only thing we need to do now is
44:40 to um use the model but we need to read the model first we need to load the model
44:46 first so let's do something as we did before I'm just going to Define it here
44:54 let's say model dict is equal to pickle load mole dot p
45:03 and then let's say model equal to model dict
45:11 model and obviously I need to import pickle
45:17 okay and this should be enough now we are here yes we are here and we need to
45:25 um uh use model to predict the category so
45:31 let's see what happens this will be in p Us are right
45:37 from data Alex okay we need to import mp2
45:47 okay and let's see let's see what happens let's see if we don't get any
45:52 error okay we get an error of course and it's
46:00 related to the shape if I'm not mistaken what we need to do now is to input this
46:07 as a list let's see what happens now
46:15 yeah everything is okay so now we are using our classifier in order to classify the class for these landmarks
46:25 we are we have like a very like a more poor performance now now it's better it
46:31 seems the classification is not making this real time maybe if I do something like waiting only one millisecond
46:39 it's not like it's the most important thing but just so we can have like a more real-time detection now it's a
46:46 little better remember I'm also recording my screen so that takes resources that's pretty much the reason
46:52 I think so let's continue everything seems to be working properly and what we will do now
47:00 now that we have our our prediction this is our prediction
47:06 we are going to draw the prediction on top of our frame or actually what we can
47:12 do we can define a dictionary which is something like labels digged and this is
47:22 0 equal to a remember the number zero represents the a character then one
47:29 represents B and then two
47:34 sorry I'm doing things wrong and two represents l
47:43 okay and what I can do now
47:48 [Music] um something like predicted
47:54 character it's equal to
48:00 um labels digged int prediction
48:07 zero because we are getting a list prediction is a list of only one element
48:13 so we need to do it this way okay that's pretty much all let's print
48:20 predict this character I'm super excited let's see if this works I'm super
48:26 excited so I press play and now let's see if we can accurately detect and
48:33 recognize all the symbols we have just trained so the first one is the ah I
48:38 have to put my run again and if I do the a character you can see
48:45 I'm getting a once and again I'm getting a so everything seems to be working properly now I'm doing the B and you can
48:52 see I'm doing I'm getting B once and again I'm getting B and everything goes perfect and if I do L which is this
49:00 value you can see I'm getting the L and also the accuracy it's perfect so that's
49:05 pretty much all because it seems everything is working super super properly the only thing we're going to do now is to make a more pretty drawing
49:13 right let's just print the um the prediction on top of the frame and let's
49:18 do also like a bounding box around the prediction around the hand we already
49:23 take things so that's what we are going to do now but you can see that we have solved the problem we have completed all
49:30 the different steps we have train the classifier and now we are testing the classifier and everything seems perfect
49:35 we are testing this classifier with live data and everything seems perfect so the
49:41 only thing we're going to do now is to do called rectangle and we are going to input frame
49:49 and then we're going to input a two values which are X1
49:58 and X2 and then we're also going to input sorry this is y1 and this is X2 Y2
50:09 a color which I'm going to Define in Black because we have too many colors right
50:14 ready in this picture in this frame with all the landmarks and so on so I'm just going to set it in Black
50:20 and then the thickness value which will be I don't know four something before
50:26 and I'm just going to do this now and I'm going to [Music] um
50:33 I'm going to Define X1 and X when y1 and X2 and Y2 in a minute but let's just
50:40 continue for now and I I want to call put text and I have a pulled text here so I'm just going to copy paste and I'm
50:47 going to [Music] um edit it with these values
50:53 this is going to be the class we already take it in so it's exactly this
51:01 then this will be here remember we have solved this problem so
51:08 we should be super super happy this is only a detail to make a very pretty drawing but everything is sold
51:15 everything is perfect so we are drawing a rectangle and we also put in the text on top of this rectangle with the class
51:22 we are predicting and now we have to Define these values in order to find these values the way
51:28 I'm going to do it I'm going to Define two additional arise
51:33 which is here X and Y I think this will be the easiest way to
51:40 solve this problem so I'm just I have defined these two auxiliary arise and
51:45 I'm going to say x dot append X and then y dot append and Y
51:54 and I'm going to say something like X1 equal to
52:01 the minimum value of x yes
52:09 then y1 is exactly the same for y and
52:15 then X2 and Y2 are the maximums
52:22 remember we are trying to get the corners of the rectangle contained in the hand
52:29 and we're also um so we know exactly where to display this rectangle and this text so this
52:36 should do but we need to do something else because if you remember the values
52:42 we were getting for the landmarks everything is in a in a float everything is float so we need to convert it into
52:49 an integer and the way we're going to do it is by calling uh we are going to get the frame shape
52:59 everything's okay and then we are just going to multiply this value times the
53:05 width of our image and we are multiplying the solar value
53:10 times the height uh we need to cast everything as an
53:16 integer and this should be enough
53:22 let's see how it performs this is not necessary
53:29 and and okay okay let's see let's see if it works or
53:36 or if we need to adjust something else okay X1 is not defined okay so the
53:42 problem is that if we are not detecting any hands right if the if there's not any hand in the frame then we never
53:49 execute this Loop we never Define these variables and we cannot draw the rectangle Lambda text in the location we
53:56 specify so doing something this should be enough now let's execute it again and
54:01 I'm just going to do an a and you can see that I'm classifying the
54:07 a super super properly now I'm going to do a b and now I am going to do an l and
54:13 everything is okay I'm going to adjust a very very small detail which is I am
54:18 going to do this drawing in a slightly different position I have already been testing different values and if I do it
54:25 here in -10 everything is going to look much much nicer and I'm going to do this in y1
54:33 -10 if I'm not mistaken sorry sorry sorry I'm a mistake it's the older one
54:38 the text one y1 minus 10 if I execute it again
54:45 everything is going to look a little nicer so they say you can see now we are seeing the A on top of the bounding box
54:52 this is B and this is L so everything is working super super purpley and that's
54:59 going to be all for this tutorial so let's go into your for today my name is Philippe I'm a computer vision engineer
55:05 if you enjoyed this video I invite you to click the like button and I also invite you to subscribe to my channel in
55:11 this channel I usually make tutorials cooling tutorials which are exactly like this one and I also share my experience
55:18 as a computer vision engineer so if these are the type of videos you're into I invite you and you're super super
55:24 welcome to subscribe to my channel this is going to be your for today and see you on the next video
55:33 [Music]
0:00 so this is exactly a project in which we will be working today you can see that this is a sign language detector we are
0:06 currently detecting different signs I am doing with my hands these are three signs I have selected from the American
0:11 sign language alphabet from this alphabet I have over here I have selected the letter A the letter b and
0:17 the letter L but obviously we could apply exactly the same process to absolutely any other symbol absolutely
0:24 any other sign from this alphabet or from any other sign language alphabet from any other country so this is
0:30 exactly a project in which we will be working on today's tutorial this will be 100 in Python we are going to be using
0:37 opencv media pipe we are going to be addicting the landmarks from our hands so this is going to be an amazing
0:42 tutorial and let's get started so this is exactly the project in which we are going to be working today and now let me
0:49 show you the pycharm project I created for today's tutorial we are going to work with these three requirements
0:56 obviously please remember to install these requirements before starting with this tutorial we are going to work with
1:01 opencv media pipe this is a very important Library we are going to use today and we're also going to work with
1:06 ckit learn so these are the requirements for today's tutorial and now let me tell
1:12 you about the project about the processing which we are going to be working today this will be a three steps
1:18 process and this is actually a very classical machine learning process we are going to start with the data
1:24 preparation the data creation then we're going to train the model and then we're going to test how this model performs so
1:31 these are the three steps in which we are going to be working today now in order to get started with this
1:37 tutorial I have already created a script which is going to be super super helpful in order to create our data set this is
1:44 a script I have already created so we can save some time while we are working
1:49 onto this tutorial so we can focus our energy on everything else because everything else will be much much more
1:55 important so you can see that this is my webcam and I have a message on my webcam saying ready and if ready press the
2:02 letter Q so the way we are going to use this script the way we are going to use this uh webcam is that we are going to
2:10 collect many different samples of the three symbols I shall show you right so
2:16 what I'm going to do is for example for the letter A for this symbol which represent the letter A I'm going to do
2:21 many times I'm going to do this process I'm going to move my hand towards the
2:26 camera and away from the camera and this way what I'm going to do is to create many different samples many different
2:33 examples of how the leather a it looks like right remember we are building a
2:39 classifier and the way classifiers work classifiers need data and the more data
2:44 we have or the more diverse data we have is going to be much better so I am going to do this this process
2:50 for the letter A then I'm going to repeat the same process for the letter b and then I'm going to do exactly the
2:55 same process for the letter L so we are going to repeat this process for these three symbols and this way we are going
3:01 to collect our data we are going to generate our data set that we are going
3:07 to create in order to work on today's tutorial so the idea is that once I'm ready I press the letter q and I start
3:13 collecting symbols I start collecting frames for all these different symbols so let's start there I'm going to press
3:19 the letter q and I'm going to move my hand towards the camera and away from the camera
3:25 and that's it so now I'm going to move to the next symbol which is something
3:31 this and I'm going to move my hand towards the camera and away from the camera
3:36 and I'm going to look for a few seconds and that's pretty much all I'm going to do the same with the letter L and I'm
3:44 going to move my hand towards the camera and away from the camera and I'm going to show you in a few
3:50 seconds how this data looks like so this is pretty much all now let's go to this project directory and I'm going to open
3:58 data and you can see I have three directories uh the directory called zero
4:04 another one called one another one called two and these are the three classes we are
4:10 going to generate we are going to classify today each one of these classes is encoded into a number into each one
4:15 of these numbers and if I open one of these directories you can see that this is me
4:21 just doing the exact process I just did just moving my camera towards the camera and away from the camera while I was
4:28 talking to you in this video so these are the samples these are the images I have just generated and for each one of
4:34 these directories I have 100 images right so I have collected 100 samples
4:40 from each category from each class I'm going to show you for the last class
4:47 which is exactly same idea but for the letter L so this is exactly a data we
4:53 are going to use in order to train or classifier and one of the things I want you to take from this video is that when
5:00 you are working on a computer vision project or actually any type of project when you are approaching a project when
5:06 you want to build a solution then there will be many many many many many many
5:11 many many different ways to build this solution there will be many different approaches you could take in order to
5:18 solve the problem that will be always the case given a problem there will be many many many
5:24 many many many possible solutions and the idea is that when you are just
5:29 sorting on a project the idea is that you consider some of these Solutions you just uh consider all the different ways
5:37 or some of the possible ways to solve the problem and then you decide for the most promising approach for the most
5:44 promising way right for example in this case one of the ways we could solve this
5:49 problem is by building an image classifier so if I open one of the frames for each category you
5:57 are going to see that let me do something like this one next to the
6:03 other so I can show you exactly what I mean one of the ways we could solve this
6:09 problem is by building an image classifier that takes the entire image
6:14 the entire frame as input and this image classifier to classify each one of these
6:20 frames into different categories so for example this image the entire image could be the letter A then this other
6:28 image will be the letter b and then this other image will be the letter L and so on right we could label the entire frame
6:36 with the category with the symbol we want to classify that will be a way to
6:41 do it that would be an approach then another approach will be to crop the image and to consider only the symbol we
6:50 want to detect right so for example in this case we will make this crop in this
6:55 other case we will make this over crop or something like it or something like this and then in this
7:02 whole case we will make this over crop right so in each case we will be using
7:08 the same approach in terms of using an image classifier but we will be classifying uh different things right or
7:16 we will be classifying only a curve from the entire frame so this will be another way to solve the problem and I think it
7:22 makes sense it will be a very a good way to solve the problem I'm sure we will achieve a very very high accuracy and
7:29 I'm sure we will achieve a perfect performance because it looks like a very good way to solve this volume but
7:36 another approach is to instead of using the entire image or instead of using an
7:43 image we could extract the information we care about this image which is only
7:48 the position of the hand right because if you realize for each one of these js2s or for each one of these symbols
7:55 all the information is in the position in the post sure of all the different
8:01 fingers and my hand and and so on right if you think about all the different symbols I show you when we started this
8:08 tutorial you will notice that all of these symbols the only difference between them or actually the information
8:14 in each one of these symbols is how the hand is located and how the fingers are
8:20 located and if you think about your fingers or if you think about a person's fingers there there are not many
8:28 situations or the movement we can do with our fingers is very constrained because we only have some possible
8:35 movements right so basically all the information in our hands it's in the
8:40 landmarks so if we use a landmark detector we will be extracting all the
8:46 information we care about these pictures these images and we will be
8:51 converting transform in each one of these images into a collection of points into something like 20 points or
8:59 something that I don't remember exactly how many landmarks are defined in the hand for the models we are going to use
9:05 today but it's something around 20 points so we will be taking an entire image of 640 times 480 pixels and we
9:16 will be reducing all that image which is actually a vgr image so it's this size
9:22 multiplied by three we will be taking this entire image and we will be transforming it into an array of
9:29 something like 20 points or 30 points or something in that so that's a very good
9:34 transformation because we are reducing the the space the input space the the
9:41 the data we are going to classify we are applying a dimensionality reduction technique because we are reducing the
9:46 dimensionality of our data while keeping the same information that's very important so that will be another
9:53 approach that will be another way to solve this problem and that's actually the way we are going to solve it that's
9:58 basically the classifier we are going to be building today so that's basically
10:03 something I think is very important I think it's one of the ways I want you to one of the things I want you to take from this video is that giving a problem
10:11 giving a project there are many many many many different ways to solve it and
10:16 it's very interesting and it's a very good exercise to consider all the different ways or some of the different
10:22 ways to solve it and to choose the most promising one that's one of the things I want you to
10:28 take from today's tutorial in this case we will we could classify the entire
10:33 image we will classify only a crop of the entire image or we could take the
10:39 landmarks of the hand in each one of these images and we just classify the landmarks and that's uh from my
10:46 perspective it's a much better approach because the classifier is going to be much
10:52 smaller and it will be much more robust as well because the input of this classifier will be the information it
10:59 needs in order to make a classification right it will be only the position of all the different fingers and the hand
11:04 and so on and we will be removing all the unnecessary information like all the pixels and the hand and the background
11:12 and me and everything else which is completely unnecessary in order to make the classification right so that's the
11:19 approach we are going to be taking today and this is the data in which we are going to be working into this tutorial
11:25 now in order to extract the landmarks and in order to move forward with the approach I described we are going to
11:32 take all the images and we are going to do some post processing we are going to process all these images so we create
11:38 exactly a data we need in order to train this classifier and the first thing I'm going to do is to import media pipe as
11:46 MP this is one of the libraries we are going to use then I'm also going to import CB2 cool
11:53 and I am going to import OS okay
12:00 and now what we are going to do is we are going to iterate in all the frames in all the images I show you a few
12:06 minutes ago and we are going to extract the landmarks from each one of these images and we are also going to save all
12:12 this data into a file we are later going to use in order to train or classifier
12:18 so let's start with that the data there I'm going to Define a variable which is
12:24 data there and this is targeted here okay then I am going to iterate in all
12:30 the directories in data there so this will be for during
12:36 foreign and I will
12:43 um iterate in all the frames Within These directory so this is something like a four image Parts in
12:53 all list here or part join data here
13:04 okay and and I'm going to Define this image but
13:12 as dot part join data dear dear and image part
13:21 and I'm going to create a variable which is image and image will be seeing a CV2
13:26 in read and this image part okay now I'm going to convert image into VAR or
13:33 actually into RGB it's already into bdr because we need to convert this image
13:39 into RGB in order to input the image into media pipe when we are working with
13:45 with media pipe all the landmark detection is always on RGB so as we are reading image in vgr we definitely need
13:52 to convert it into RGB so this will be CV to convert color
13:58 color [Music]
14:05 bgr2 RGB okay so this is pretty much all so this is
14:11 the images we are reading from our data directory and now I'm going to import
14:17 multiple live dot Pi plot because let's plot how these images look
14:24 like I am going to extract landmarks in a few minutes but for now let's just plot these images in order to make sure
14:29 everything is working properly so I'm just going to upload a few
14:34 I'm going to plot one for each directory so I am going to do something like this
14:42 so I only take the first one okay and now this is in show image RGB
14:51 remember that a metal Leaf also requires the image into RGB in order to plot this
14:57 image using battle leave this will be plot dot figure
15:04 and then plot.show and let's see what happens let's see if everything is working properly
15:13 okay perfect so we are plotting a frame from each class
15:18 from the three directories and everything seems to be working properly so far and now let me show you three
15:24 objects we are going to use which are these three sentences I have over here I'm just going to copy and paste
15:31 everything everything is already ready in this notepad so we don't really lose time defining these objects and this is
15:38 basically the three objects which are going to be super super useful in order to detect all the landmarks and in order
15:43 to draw these landmarks on top of the images we don't really need to draw the landmarks on top of the images in order
15:50 to do our classification but I'm going to to do it only to show you how these landmarks look like so these are the
15:56 three objects we are going to use and now let's define an object the hand
16:03 detector which is something like this this will be if I'm not mistaking a p
16:10 dot hands dot hands and then the variables are something
16:16 like study image mode true and then confidence mean detection
16:23 confidence which is we're going to use 0.3 okay so this is the model we are
16:29 going to use and now going back here remember this is the image this is the image we have converted into RGB and now
16:36 we are going to do something like this we're going to say hands.process and we're going to take this image here
16:43 and what we are doing here
16:48 is to detect all the landmarks into this image right that's exactly what we are
16:55 doing with this sentence and now the only thing we need to do is to iterate in the landmarks in all the landmarks we
17:02 have detected in this image and for that maybe the best way to do it in order to move one step at a time is to show you
17:08 how these landmarks look like so let me get back here and I am just going to
17:14 copy and paste this function which is going to be a much it's a much better
17:20 way to do it I'm just going to copy and paste it so we don't really lose time to coding this um
17:26 function from scratch so basically you can see that this is iterating in all
17:31 the results we have from this hand detection we are doing here because
17:38 remember we could be attacking only one hand or two hands or no hands at all so it makes perfect sense to iterate in all
17:45 the different results and then for each one of our results we are going to draw the landmarks and this is basically the
17:52 way to do it by calling these functions with this function with these arguments remember everything will be available in
17:58 the repository for today's tutorial so you can just take all the code from this repository and you can just take
18:05 everything from there from now for now just follow along so you should come follow the entire process and then you
18:12 can just go back to The Code by looking at the repository so this is the landmark drawing and this will be pretty
18:20 much all if I'm not mistaken let me just run this code to see what happens I have to do something else which is I need to
18:27 ask if we have detected at least
18:33 one hand right because we could be detecting no hand at all and that
18:41 that could be a problem for what we are going to do later on so let's just run
18:46 this script let's see what happens we are perfect just perfect you can see
18:54 that we are detecting exactly the position of the hand and we are just
19:00 detecting exactly all the different landmarks you can see that we have many different colors the style we are using
19:06 in order to the in order to draw these landmarks it's just it's giving us all these different colors so we know
19:12 exactly all the different fingers and so on so these are exactly the landmarks we
19:19 are going to use into this tutorial we are going to take all this information and we are going to
19:26 draw the we're going to build our classifier with this information so this is only to show you how these landmarks
19:32 look like and this is what I mean when I say that these landmarks contain absolutely all the information we need
19:38 in order to work on this tutorial in order to build this classifier because Take a Look only at the landmarks don't
19:45 take a look at the image itself at my hand but take a look only at the landmarks and you can see that all the
19:52 information we need it's in the landmarks right for example in this case for classifying the L we will need to
19:58 take a look what happens here what happens in this section with these four landmarks if we
20:06 have a situation like this where this finger it's like up and then all the other fingers are down then that's
20:13 pretty much all we need to know in order to make this classification and then if we go here if we notice these four
20:20 fingers are up this means we are in this situation and if we are in this sort of
20:25 situation with all the different fingers like this then we are here but absolutely all the information we
20:31 need is in the landmarks so it is only to show you how it looks like and it
20:36 will be exactly the same situation with absolutely any other symbol we choose the information will be in the landmarks
20:43 and now let's continue we don't really need to do the drawing the only reason I did the drawing was only to show you how
20:49 this looks like but we don't really need it so let's continue what we are going to do now is uh yeah I'm just going to
20:55 remove this part yeah because we don't really need I'm going to remove all the drawing I'm going to keep everything
21:02 else and what I'm going to do is I'm going to take the the entire landmarks
21:07 and I'm going to create an arrive from all the landmarks right I'm going to take all the image and from each image I
21:15 want to have an array with the information of absolutely all the landmarks we have detected right so in
21:22 order to go one step at a time I'm going to iterate for e in range uh the length of Handler marks.land mark
21:33 and I'm going to show you how these look like I am going to print this value and this is going to give us the value of
21:40 all the landmarks I'm going to show you how it looks like
21:45 first and then I'm going to do something with them
21:51 okay we don't really need to plot the images anymore but we have the images too and you can see that for each one of
21:57 these landmarks we have three values x y and sieve and these are all the values
22:04 which Define exactly the position of each one of our landmarks so we are
22:09 going to use only the X and the Y coordinates which are the horizontal and the vertical coordinates and from this
22:16 information we are going to create an array a very long array and we I think
22:22 we are going to train the classifier and we're going to inference this classifier by considering this array of landmarks
22:30 all on right so we have an image we detect the landmarks and then we take these landmarks into a very very long
22:36 array and that's there right we are going to consider in order to train our
22:41 classifier right that's a process we are taking and we are taking everything one
22:46 step at a time now we are going to access the X and the y coordinate so this will be the x coordinate and
22:54 then the y coordinate will be something like this
23:00 right and we are going to save everything into an array so I am going to create two variables which are data
23:08 and another one which is labels we don't really want to iterate in only
23:13 one image anymore so I'm going to delete that and I'm not going to plot it anymore
23:19 so we have defined these two variables which are the variables which are going to contain all the information right the
23:27 data which is the data we are going to produce in order to make this classification and then the labels which
23:33 are the category for each one of these images for each one of these data points
23:39 so this is how we're going to do it we are iterating in all the images
23:44 for each image I'm going to create an array which is data aux
23:50 and this is an empty array for now let me show you exactly what we are going to save here
23:55 this is where we are going to save the X and the Y coordinates
24:00 so
24:07 something like this X and then something like this with Y
24:12 right and then at the end of the entire iteration we are going to do something
24:18 like uh data dot append
24:24 data logs and then labels dot append
24:31 and then a deer which is the category right remember that we have three
24:38 categories we have three directories one of them is called zero the other one is called one and the other one is called two and each one of these directories
24:45 contains each one of our symbols so the symbol is encoded into the name of the
24:51 directory so this is exactly what we need to do for each one of our images we
24:56 are extracting all the landmarks we are creating a very long RPI with all these landmarks and then this very long array
25:04 is going to represent our image right we are going to create a an entire list
25:10 with all these different arise and then the labels will be the name of the
25:15 directory of each one of these images and doing so we are creating our data
25:21 set doing so we are creating the data set we need in order to train our classifier
25:26 and so that's pretty much all now let's see if this works properly because we have done many many different things and
25:34 there could be there are many places in which we could have made a mistake so
25:39 let's see what happens okay everything was successfully executed so everything seems to be okay
25:45 so what I'm going to do now is I'm going to save all this data so I'm going to do
25:51 something like this and I'm going to Define an object which is f and this is open
25:58 data dot pickle if I'm only saying I haven't imported pickles I'm going to
26:03 import it now and remember pickle is a python Library which is very commonly used for these type of situations to
26:10 save data to save data sets models and so on it's just like a way to save this
26:16 information so we are opening this file and we need to do it like this
26:24 okay because we are grating and it's also we are doing it as bytes so we need
26:29 to do it like this then we need to say pickle dot dump the object we are going to save and we
26:36 are going to create a dictionary containing these two keys
26:44 and here we will have the data and the labels we have just generated
26:49 and then we need to close the file and that's pretty much all and also we need
26:55 to input F here and that's pretty much all so let's see what happens I'm going to
27:03 run this again um and if everything runs successfully we
27:09 should have a file with this name okay everything runs successfully now if
27:15 I go to my directory I should see this file which is the file I have just
27:22 generated you can see this is my current time so this is if I did have just generated and I have other files from
27:29 all iterations or four executions where it was preparing this tutorial but this is the file they have just shared
27:35 so going back to poicharm so everything seems to be ready for now we have
27:42 created the data set this is the data we are going to use in order to train our classifier and now we can just continue
27:49 to The Next Step which is training this classifier now we are going to take the
27:54 data we are going to load this data and we're going to train a classifier with it so we are going to do exactly the
28:01 same as we are doing here but we are going to load the data instead so I am going to import pickle
28:10 is going to remove this string classifier and I am going to call
28:16 pickle.loa and this will be open the file name which is data dot pickle and
28:25 then I need to read this as RB okay and this will be our data
28:32 file or or data dictionary if I'm not mistaken this is the way to
28:39 read the data and now let's print let's print two things the keys of this
28:45 dictionary and let's also print the object data
28:51 sorry data dictionary and let's see what happens
28:58 okay everything seems to be okay these are all four labels and these are the
29:04 dictionary data these are the keys data and labels and then everything seems to
29:09 be working properly so now let's continue and let's continue by importing
29:15 all the different objects and all the different libraries we are going to use in order to train this classifier we are
29:21 going to train it using the library secret learn and we are going to use a very specific Model A very specific type
29:28 of classifier which is random Forest so let's start by importing from SQ
29:36 sklearn dot ensemble import random forest classifier and then
29:44 we're also going to import sqlarn dot model selection import train
29:52 test split and we're also going to import um from The Matrix Library
30:01 accuracy score okay so these are the three libraries we are going to use in this section in order to train this
30:07 classifier we are going to train a random forest classifier and these are two other functions we are going to need
30:13 two so let's start by and grabbing the data and the labels and this is how
30:18 we're going to do it and we're going to call that a dict and this will be
30:25 data and labels data dict
30:32 labels okay and we need to convert this into one ampere array
30:38 sorry I need to import an mp2 I'm going to do it just now
30:44 uh because we just need to import it
30:51 because this is the way this classifier works and this is why all these libraries work so I'm going to import
30:58 numpy SMP remember that currently or data is as a
31:05 list right data and labels are lists that's why we need to convert them into numpy arrays okay and the first thing we
31:13 need to do in order to train this classifier is to prepare the data so we have all four data into these two
31:20 objects data and labels now we are going to split this data into a training set
31:25 and a test set this is a very common practice when we are training a classifier any type of classifier we
31:32 usually need two sets assets we are going to use in order to train this algorithm and in another set we are
31:38 going to use in order to test the performance of this algorithm so this is what we are going to do and this is how
31:45 we're going to name this training set and this test set
31:50 um we're going to let me grade it first and I'm going to explain in a few minutes
31:55 this is something like this
32:02 this is where we're going to use this function uh we're going to input data labels
32:09 I'm just going to write everything down and I'm just going to explain it in a few minutes
32:15 um so just bear with me Shuffle it with true and then
32:22 stratify according to labels okay so what we are doing here is calling train
32:28 test split and we are splitting all of our data we are splitting all these
32:34 array and all this over array into two sets right so from the data list also
32:40 from the data array we are creating these two sets and you can see that one of them is called train and the other
32:46 one is called test and we're doing exactly the same for the labels we are creating two objects to arise one of
32:53 them is trained and the other one is test so we are taking all the information within data and labels and
33:00 we are splitting this information into two different sets let me find a picture so I can explain
33:09 this a little more so this will be a little more clear train test split I'm sure we're going to
33:15 have we're going to find many many different pictures explaining how this is done you can
33:22 consider this image so we have the entire a ride the entire day time and we
33:28 are splitting this data into two sets training set and test set so the
33:34 training set is what I have called xtrain and the test set is what I have called egg the X test that's basically
33:42 what we are doing and we are doing exactly the same process for data and labels then test size is the size of the
33:48 test set you can see that we have two sets and we can Define the size of this
33:54 test set for with different sizes right we could say this is a 10 of the data
34:00 the 20 the 50 the 80 and so on so I have specified this value in 0.2 which means
34:07 we are keeping the 20 percent of our data only the 20 percent as or test set
34:14 and 20 is a value which is very commonly used as a test
34:19 then Shuffle equal through means we are shuffling the data this is a very good
34:24 practice it's a very common practice and I will advise that you always always shuffle your data when you are doing
34:32 something like this when you are training a classifier because this is something I have mentioned I have
34:38 covered in our tutorials where I also show you how to train image classifiers or different type of classifiers and
34:45 sometimes there are different biases in our data that we are not aware of so
34:50 shuffling the data is a very common practice even when we think it's not
34:55 a long story short always remember to shuffle the data it's going to be much much further then stratify equals labels
35:03 this means that we are going to split it as a set but we are going to keep the
35:09 same proportion of the different labels of the different categories we had in this object we are going to keep exactly
35:16 the same proportion in the train set as in the test set right so this object and
35:23 this other object are going to have the same proportion of all of our different labels right so if you remember the data
35:32 we are using we have 100 elements in this category 100 elements in this or
35:38 category and 100 elements here so this means that one third of the data is
35:44 labeled as a which is this symbol one third of the data is B and one third is
35:51 L and if we look at these two objects white rain and white test we are going to see exactly same proportion one third
35:58 of all the data of all of the elements in these are I are going to be a then an
36:05 earth here will be a b and a North here with b l and exactly the same situation here so that's basically what it means
36:11 when we are stratifying according to the labels and that's also a very common practice and a very good practice when
36:17 we are splitting at asset so always remember to include stratify equals
36:23 labels when you're using trained test splits so this is all for splitting the
36:28 data and now it's time to create our model so the model we're going to use remember is a random Force classifier
36:36 so this is the classifier we are going to use and the first thing we need to do is to train this classifier so we are
36:44 going to call fit we're going to input X strain and white strain this is the way we are training this classifier this one
36:51 this is the way we are fitting this model and then we just need to call Dot
36:57 predict and we need to input X test and this will be y predict
37:04 and that's it in only a couple of lines we have
37:09 trained the classifier and we have also made our predictions this is how simple this is so let's just execute this
37:17 script to make sure everything works properly everything works properly and you may notice how fast it was right
37:24 this took only a few seconds if you are familiar with machine learning algorithms with training machine
37:30 learning algorithms you will know that sometimes it takes a lot of time to train a classifier but in this case this
37:37 is a very very fast training so that's one of the reasons I chose random 4 is
37:42 because it's like a very simple algorithm I know the training is very fast I know that it's robust enough for
37:48 or a problem for project so we have a really true in the classifier we have
37:54 all predictions and the only thing we need to do now is to see how these classifier performs so I am going to
38:03 find a new variable which is score and this will be accuracy score and I'm
38:08 going to input all predictions and then I'm going to input why tests which are all labels and now I
38:17 am going to print and this will be something like I'm
38:24 going to express it as a percentage of samples
38:31 were classified correctly
38:39 format and this is something like score something like this let's see what
38:45 percentage of our samples were classified correctly so I'm going to run
38:50 this code and you can see oh I forgot to do something which is multiplying this value times
38:59 100 you already saw the answer but anyway let's do it again 100 of our
39:06 samples were classified correctly so this is amazing this means we have a
39:12 perfect performance we have Trina classifier with a perfect performance so everything makes sense now the way we
39:19 process the data in order to extract all the landmarks for more images from our hands because that's where we had all
39:25 the information and now the selection we did for this classifier because we had
39:31 the intuition this is not really a super super complex problem and a random Forest will do just fine everything
39:37 makes sense now when we are achieving a 100 accuracy right so this is very good and
39:47 the only thing we're going to do now is to save this model the same way we save the data here we are going to save the
39:55 model because we want to use this model later on to to test the performance of
40:00 this model but not testing the performance as we did here but testing the performance of this model with real
40:07 data I am going to make some gestures some symbols and we are going to classify these symbols live on my camera
40:15 on this video so we definitely need the model I'm going to save this model like
40:20 model.pe and I'm going to do something similar I'm going to say model this will be
40:28 model on this okay so I am saving a dictionary
40:34 with only this object and I press play and that should be it we have to wait
40:40 and then it's it's completed if I go to my directory you can see the model we
40:46 have trained is here and this is my current time so everything it's okay
40:52 so everything is almost ready you only we have only one step left which is
40:57 testing this classifier so that's what we are going to do now okay now it's time to test our
41:04 classifier and the way we are going to test this classifier is by importing CV2
41:11 because we are going to access our webcam and we're here going to do all
41:16 these different symbols in our webcam and see what happens so cup will be something like CV2 video capture
41:24 and I'm going to access this webcam the number two and then while true
41:30 a cup dot read and this is red and frame
41:38 and then I am going to call CV2 IM show I'm going to call this window frame and
41:45 this will be my frame uh and then CB2 weight key
41:52 and here we should put a 25 which means we are going to wait 25 milliseconds
41:58 between each frame right so everything seems to be working fine and this is my
42:05 webcam so um what we are going to do now is we are going to detect uh all the landmarks in
42:13 this webcam we are going to detect all the landmarks of my hand and then we are going to use the classifier which is
42:18 trained in order to know what a symbol I am displaying in my hand so let's do that I am going to release memory I'm
42:26 not sure if it's reading here because we are exiting the program the the program anyway but I'm going to do it just just
42:33 because it's a good practice CV2 destroy all windows
42:38 and that's pretty much all so uh I don't have much space here
42:47 so let's go here and I'm going to copy a few
42:53 objects I'm going to copy this which is the
42:59 um the media pipe library or the media pipe functions we used
43:12 and then I am going to we also need the color conversion but
43:18 I'm going to do this okay something like this this will be frame
43:25 RGB frame frame RGB
43:31 and this is where we are going to um go through all the landmarks and
43:36 we're going to do something similar as we did before so I'm going to copy this
43:42 code I used before and the first thing we're going to do is to draw
43:47 the landmarks on top of the webcam and then we are going to classify it so as
43:53 always it's always a good idea to go one step at a time and let's just run this
43:59 code to see if everything works properly um everything seems to be working
44:05 properly you can see we are getting the landmarks from my hand and now it's the
44:11 time we are going to classify this object so we go back here and we say something
44:19 like this we are going to iterate in all the landmarks the same way we did before and now we are going to create a
44:29 no of an auxiliary array which is this
44:35 the same way we did before and the only thing we need to do now is
44:40 to um use the model but we need to read the model first we need to load the model
44:46 first so let's do something as we did before I'm just going to Define it here
44:54 let's say model dict is equal to pickle load mole dot p
45:03 and then let's say model equal to model dict
45:11 model and obviously I need to import pickle
45:17 okay and this should be enough now we are here yes we are here and we need to
45:25 um uh use model to predict the category so
45:31 let's see what happens this will be in p Us are right
45:37 from data Alex okay we need to import mp2
45:47 okay and let's see let's see what happens let's see if we don't get any
45:52 error okay we get an error of course and it's
46:00 related to the shape if I'm not mistaken what we need to do now is to input this
46:07 as a list let's see what happens now
46:15 yeah everything is okay so now we are using our classifier in order to classify the class for these landmarks
46:25 we are we have like a very like a more poor performance now now it's better it
46:31 seems the classification is not making this real time maybe if I do something like waiting only one millisecond
46:39 it's not like it's the most important thing but just so we can have like a more real-time detection now it's a
46:46 little better remember I'm also recording my screen so that takes resources that's pretty much the reason
46:52 I think so let's continue everything seems to be working properly and what we will do now
47:00 now that we have our our prediction this is our prediction
47:06 we are going to draw the prediction on top of our frame or actually what we can
47:12 do we can define a dictionary which is something like labels digged and this is
47:22 0 equal to a remember the number zero represents the a character then one
47:29 represents B and then two
47:34 sorry I'm doing things wrong and two represents l
47:43 okay and what I can do now
47:48 [Music] um something like predicted
47:54 character it's equal to
48:00 um labels digged int prediction
48:07 zero because we are getting a list prediction is a list of only one element
48:13 so we need to do it this way okay that's pretty much all let's print
48:20 predict this character I'm super excited let's see if this works I'm super
48:26 excited so I press play and now let's see if we can accurately detect and
48:33 recognize all the symbols we have just trained so the first one is the ah I
48:38 have to put my run again and if I do the a character you can see
48:45 I'm getting a once and again I'm getting a so everything seems to be working properly now I'm doing the B and you can
48:52 see I'm doing I'm getting B once and again I'm getting B and everything goes perfect and if I do L which is this
49:00 value you can see I'm getting the L and also the accuracy it's perfect so that's
49:05 pretty much all because it seems everything is working super super properly the only thing we're going to do now is to make a more pretty drawing
49:13 right let's just print the um the prediction on top of the frame and let's
49:18 do also like a bounding box around the prediction around the hand we already
49:23 take things so that's what we are going to do now but you can see that we have solved the problem we have completed all
49:30 the different steps we have train the classifier and now we are testing the classifier and everything seems perfect
49:35 we are testing this classifier with live data and everything seems perfect so the
49:41 only thing we're going to do now is to do called rectangle and we are going to input frame
49:49 and then we're going to input a two values which are X1
49:58 and X2 and then we're also going to input sorry this is y1 and this is X2 Y2
50:09 a color which I'm going to Define in Black because we have too many colors right
50:14 ready in this picture in this frame with all the landmarks and so on so I'm just going to set it in Black
50:20 and then the thickness value which will be I don't know four something before
50:26 and I'm just going to do this now and I'm going to [Music] um
50:33 I'm going to Define X1 and X when y1 and X2 and Y2 in a minute but let's just
50:40 continue for now and I I want to call put text and I have a pulled text here so I'm just going to copy paste and I'm
50:47 going to [Music] um edit it with these values
50:53 this is going to be the class we already take it in so it's exactly this
51:01 then this will be here remember we have solved this problem so
51:08 we should be super super happy this is only a detail to make a very pretty drawing but everything is sold
51:15 everything is perfect so we are drawing a rectangle and we also put in the text on top of this rectangle with the class
51:22 we are predicting and now we have to Define these values in order to find these values the way
51:28 I'm going to do it I'm going to Define two additional arise
51:33 which is here X and Y I think this will be the easiest way to
51:40 solve this problem so I'm just I have defined these two auxiliary arise and
51:45 I'm going to say x dot append X and then y dot append and Y
51:54 and I'm going to say something like X1 equal to
52:01 the minimum value of x yes
52:09 then y1 is exactly the same for y and
52:15 then X2 and Y2 are the maximums
52:22 remember we are trying to get the corners of the rectangle contained in the hand
52:29 and we're also um so we know exactly where to display this rectangle and this text so this
52:36 should do but we need to do something else because if you remember the values
52:42 we were getting for the landmarks everything is in a in a float everything is float so we need to convert it into
52:49 an integer and the way we're going to do it is by calling uh we are going to get the frame shape
52:59 everything's okay and then we are just going to multiply this value times the
53:05 width of our image and we are multiplying the solar value
53:10 times the height uh we need to cast everything as an
53:16 integer and this should be enough
53:22 let's see how it performs this is not necessary
53:29 and and okay okay let's see let's see if it works or
53:36 or if we need to adjust something else okay X1 is not defined okay so the
53:42 problem is that if we are not detecting any hands right if the if there's not any hand in the frame then we never
53:49 execute this Loop we never Define these variables and we cannot draw the rectangle Lambda text in the location we
53:56 specify so doing something this should be enough now let's execute it again and
54:01 I'm just going to do an a and you can see that I'm classifying the
54:07 a super super properly now I'm going to do a b and now I am going to do an l and
54:13 everything is okay I'm going to adjust a very very small detail which is I am
54:18 going to do this drawing in a slightly different position I have already been testing different values and if I do it
54:25 here in -10 everything is going to look much much nicer and I'm going to do this in y1
54:33 -10 if I'm not mistaken sorry sorry sorry I'm a mistake it's the older one
54:38 the text one y1 minus 10 if I execute it again
54:45 everything is going to look a little nicer so they say you can see now we are seeing the A on top of the bounding box
54:52 this is B and this is L so everything is working super super purpley and that's
54:59 going to be all for this tutorial so let's go into your for today my name is Philippe I'm a computer vision engineer
55:05 if you enjoyed this video I invite you to click the like button and I also invite you to subscribe to my channel in
55:11 this channel I usually make tutorials cooling tutorials which are exactly like this one and I also share my experience
55:18 as a computer vision engineer so if these are the type of videos you're into I invite you and you're super super
55:24 welcome to subscribe to my channel this is going to be your for today and see you on the next video
55:33 [Music]
